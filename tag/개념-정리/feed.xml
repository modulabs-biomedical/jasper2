<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>http://localhost:20010/</title>
   
   <link>http://localhost:20010/</link>
   <description>모두의연구소 바이오메디컬랩 기술 블로그입니다.</description>
   <language>en-uk</language>
   
   <title>
   <![CDATA[ 바이오메디컬랩@모두의연구소 ]]>
   </title>
   <description>
   <![CDATA[ 모두의연구소 바이오메디컬랩 기술 블로그입니다. ]]>
   </description>
   <link>http://localhost:20010/</link>
   <image>
   <url>http://localhost:20010/assets/images/favicon.png</url>
   <title>바이오메디컬랩@모두의연구소</title>
   <link>http://localhost:20010/</link>
   </image>
   <generator>Jekyll 3.6.2</generator>
   <lastBuildDate></lastBuildDate>
   <atom:link href="http://localhost:20010/rss.xml" rel="self" type="application/rss+xml"/>
   <ttl>60</ttl>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>TensorPack</title>
	  <link>http://localhost:20010/TensorPack</link>
		
				
		
				
		
				
		
				
		
				
						<author>차예솔</author>
				
		
				
		
				
		
				
		
				
		
	  <pubDate>2018-08-17T09:00:00+09:00</pubDate>
	  <guid>http://localhost:20010/TensorPack</guid>
	  <description><![CDATA[
	     <h1 id="tensorpack-구조-이해하기">Tensorpack 구조 이해하기</h1>

<h5 id="modeldesc와-trainer를-중심으로">ModelDesc와 Trainer를 중심으로</h5>

<h3 id="peter-cha">Peter Cha</h3>

<h2 id="tensorpack을-공부하면-">Tensorpack을 공부하면, 😐</h2>

<ul>
  <li>우선 모르는 것들 투성이다. 알고나면 너무 쓰기 편하지만, 처음 접할 때는 너무 많이 추상화 된 API에 ‘이게 tensorflow는 맞는지..’할 정도니까.</li>
  <li>우선 이 튜토리얼을 보기 전, 필자의 <a href="https://github.com/PeterCha90/Tensorflow-Deep-Learning/blob/master/Tensorpack_tutorial.ipynb"><code class="highlighter-rouge">tensorpack_tutorial.ipynb</code></a>를 먼저 보길 바란다. 대략적인 dataflow는 데이터를 불러오는 부분으로 이해를 마쳤다고 생각하고, dataflow부분은 생략하고 설명을 진행하도록 하겠다.</li>
  <li>이번에는 Model의 선언하게 될 때 상속받은 <strong><code class="highlighter-rouge">ModelDesc</code></strong> class와, 학습을 실행하는 Trainer들의 모태가 되는 <strong><code class="highlighter-rouge">TowerTrainer</code></strong> 에 대해 알아보고자 한다.<code class="highlighter-rouge">tensorpack_tutorial.ipynb</code>에서 설명에 해당하는 부분을 함께 찾아보면 이해에 도움이 더 될 것 같다.</li>
  <li>이 Tutorial은 Tensorpack <a href="https://tensorpack.readthedocs.io/modules/train.html?highlight=TowerFuncWrapper">documentation</a>을 참고해서 만들었다.</li>
</ul>

<p><br /></p>

<h2 id="1-class-modeldescbase-">1. Class <code class="highlighter-rouge">ModelDescBase</code> 😏</h2>

<blockquote>
  <p>Base class for a model description이다.</p>
  <ul>
    <li><code class="highlighter-rouge">ModelDesc</code>는 ModelDescBase를 기반으로 만들어졌기 때문에, <code class="highlighter-rouge">ModelDescBase</code>를 먼저 설명한다.</li>
  </ul>
</blockquote>

<h3 id="11-build_graphargs">1.1. build_graph(*args)</h3>

<ul>
  <li>모든 symbolic graph (<strong>Model의 형태</strong>)를 Build한다. 이 함수가 뒤에서 설명할 <code class="highlighter-rouge">TowerTrainer</code>에서 <code class="highlighter-rouge">tower function</code>의 일부분이다.</li>
  <li>그 다음 설명할 <code class="highlighter-rouge">inputs()</code>에서 정의된 input list에 맞는 <code class="highlighter-rouge">tf.Tensor</code>를 parameter로 받는다.</li>
  <li>아무것도 리턴하지 않는다.</li>
</ul>

<h3 id="12-inputs">1.2. inputs()</h3>

<ul>
  <li>Model에서 input으로 받을 텐서들의 placeholder들을 정의하는 함수다.</li>
  <li>후에 <code class="highlighter-rouge">InputDesc</code>로 변환될, <code class="highlighter-rouge">tf.placeholder</code>들을 return 한다.</li>
</ul>

<p><img src="../assets/images/posts/2018-08-17-TensorPack/modeldesc.png" alt="u-net_fig_2" /></p>

<h3 id="13-get_inputs_desc">1.3. get_inputs_desc</h3>

<ul>
  <li>이름에서 알 수 있듯이, inputs()에서 정의된 모양대로 생긴 InputDesc를 list로 반환하는 함수다.</li>
</ul>

<p><br /></p>

<h2 id="2-class-modeldesc-">2. Class <code class="highlighter-rouge">ModelDesc</code> 😎</h2>

<ul>
  <li><strong>주의사항</strong>: <strong>build_graph()를 꼭 cost를 return하도록</strong> 코딩해야 한다.</li>
  <li>앞에서 설명한 ModelDescBase를 상속받은 터라, 위의 3가지는 함수는 내장하고 있다.
    <h3 id="21-optimizer">2.1. optimizer()</h3>
  </li>
  <li><code class="highlighter-rouge">tf.train.Optimizer</code>를 여기에 선언해주고 Return하게끔 함수를 짜준다.
    <h3 id="22-get_optimizer">2.2. get_optimizer()</h3>
  </li>
  <li>optimizer()를 호출하면, 계속 새로 optimizer를 만들어서 생성하는데, 이 함수를 쓰면 이미 optimizer()를 통해 생긴 optimizer를 기록해 놓았다가 반환시켜준다.</li>
</ul>

<p><br /></p>

<h2 id="3-class-towertrainer-">3. Class <code class="highlighter-rouge">TowerTrainer</code> 😶</h2>

<h3 id="tensorpack에서는">Tensorpack에서는,</h3>

<ul>
  <li>우리가 흔히 말하는 Model을 계속 Tower라고 지칭한다.(왜 그런지 모르겠다.:no_mouth:)</li>
  <li>그래서 아래에서 나오는 <code class="highlighter-rouge">TowerTrainer</code>는 만든 모델을 학습을 시키는 <strong>Trainer</strong>고, 그 트레이너가 어떤 특징들을 가진 함수들을 들고 다니는지 생각하면 이해가 쉽다.</li>
  <li>기본적으로 <u>Tensorpack에 나오는 모든 Trainer들은 `TowerTrainer`의 subclass다</u>. 이 개념이 그래서 궁극적으로는 모든 neural-network training을 가능하게 해준다.</li>
</ul>

<h3 id="31-get_predictorinput_names-output_names-device0">3.1. <code class="highlighter-rouge">get_predictor</code>(input_names, output_names, device=0)</h3>

<blockquote>
  <p>Returns a callable predictor built under <code class="highlighter-rouge">TowerContext(is_training=False)</code>.</p>
</blockquote>

<ul>
  <li>이 함수가 호출되면, 가지고 있는 TowerContext(모델의 Train or Test 여부)를 <u>training mode가 아닌 상태(is_training=False, 즉=Test 모드)</u>로 돌려준다. 그러니까 <strong>Test data로 시험할 때만 부르는 함수</strong>. 그래서 이름도 predictor.</li>
  <li><strong><code class="highlighter-rouge">Parameters</code></strong>: <code class="highlighter-rouge">input_names</code> <strong>(list)</strong>, <code class="highlighter-rouge">output_names</code> <strong>(list)</strong>, <code class="highlighter-rouge">device</code> <strong>(int)</strong> – build the predictor on device ‘/gpu:{device}’ or use -1 for ‘/cpu:0’.</li>
  <li>파라미터로 들어가는 input, output이름은 모델 안에서 선언된 이름이 아니면 안 돌아가니까 조심.</li>
</ul>

<h3 id="32-inputs_desc">3.2. inputs_desc</h3>
<blockquote>
  <p>Returns – list[InputDesc]: metainfo about the inputs to the tower.</p>
</blockquote>

<ul>
  <li>말 그대로, 모델에 들어갈 Input의 크기와 같은 정보가 들어있는 list를 반환해준다.</li>
</ul>

<h3 id="33-tower_func">3.3. tower_func</h3>
<blockquote>
  <p>Build Model.</p>
  <ul>
    <li>이 친구가 실제 <strong>모델을 정의하고, Build</strong>할 수 있는 함수를 세팅하는 부분!</li>
    <li><strong><code class="highlighter-rouge">ModelDesc</code></strong> interface로 정의된 model을 trainer로 돌려야 하는 상황이 자주 발생할 수 있는데, 이 때, <u>ModelDesc에서 선언된 **build_graph 함수**가 이 역할을 대신</u>해 줄 수 있다.</li>
  </ul>
</blockquote>

<h3 id="34-towers">3.4. towers</h3>
<blockquote>
  <p>Returns – a TowerTensorHandles object, to
access the tower handles by either indices or names.</p>
  <ul>
    <li>모델 및 Train 전반에 걸쳐 관련된 변수들에 접근하고 싶을 때 사용한다! 그래서 이 함수는 Transfer learning을 할 때 유용할 거 같다.</li>
    <li>이미 <strong>모델 그래프가 Set up이 끝난 뒤에만</strong> 이 함수는 호출될 수 있다.</li>
    <li>각각의 <code class="highlighter-rouge">layer</code>와 <code class="highlighter-rouge">attributes</code>에 이 <code class="highlighter-rouge">towers</code>함수를 호출하면 접근할 수 있게 된다! 아래는 예시.</li>
  </ul>
</blockquote>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Access the conv1/output tensor in the first training tower
trainer.towers.training()[0].get_tensor('conv1/output')
</code></pre></div></div>

<p><br /></p>

<h2 id="4-class-trainer-">4. Class <code class="highlighter-rouge">Trainer</code> 🙄</h2>

<blockquote>
  <p>Base class for a trainer.</p>
  <ul>
    <li>분명히 위에서 금방, 
“기본적으로 <u>Tensorpack에 나오는 모든 Trainer들은 `TowerTrainer`의 subclass다</u> “</li>
  </ul>
</blockquote>

<p>라고 했는데, 이 <code class="highlighter-rouge">TowerTrainer가 상속을 받는 class</code>가 있었으니, 이름하여 TowerTrainer보다 더 단순한 <strong><code class="highlighter-rouge">Trainer</code></strong> 다.</p>
<ul>
  <li>다른 TowerTrainer를 상속 받은 Trainer들을 사용할 때, 종종 TowerTrainer에서 본 적 없는 친구들이 나타나는데, 그 친구들이 Trainer의 것인 경우가 있다.</li>
  <li>하지만, Trainer 고유 함수나 요소에 직접적으로 접근할 일이 별로 없어서 아래의 3가지 정도만 알고 있으면 될 것 같다. 나머지는 <a href="https://tensorpack.readthedocs.io/modules/train.html?highlight=register_callback#tensorpack.train.Trainer">문서</a>를 참고하자.</li>
</ul>

<blockquote>
  <p>아래 1, 2번의 max_epoch과, steps_per_epoch은 <code class="highlighter-rouge">TrainConfig</code>에서 자주 만나는 키워드들인데, 이 친구들이 Trainer의 요소였다.</p>
</blockquote>

<h3 id="41-max_epoch">4.1. max_epoch</h3>
<ul>
  <li>Epoch은 몇 번 돌릴 것인지</li>
</ul>

<h3 id="42-steps_per_epoch">4.2. steps_per_epoch</h3>

<ul>
  <li>한 에폭당 steps은 총 몇 번인지.</li>
</ul>

<p><img src="../assets/images/posts/2018-08-17-TensorPack/sample.png" alt="u-net_fig_2" /></p>

<h3 id="43-register_callbackcb">4.3. register_callback(cb)</h3>
<blockquote>
  <p>Register callbacks to the trainer. It can only be called before Trainer.train().</p>
  <ul>
    <li><u>Trainer가 모델을 돌릴 때마다(epoch이 진행 됨에 따라), 수행하게 될 부가적인 기능</u>들을 Tensorpack에서는 <strong>callback</strong>이라고 부르고, 대표적인 callback으로 <strong>ModelSaver()</strong> 가 있다.</li>
    <li>이 Callback을 명시적으로 전달하여 Trainer Object에 세팅할 수 있는 기능이다. 주로 모델을 튜닝할 때, 설정하면서 종종 쓰는 것을 코드 상에서 확인할 수 있다.</li>
  </ul>
</blockquote>

<p><br /></p>

<h2 id="5-towercontext-">5. TowerContext 😛</h2>

<ul>
  <li><strong><code class="highlighter-rouge">TowerContext</code></strong> 는 Training과 Validation 혹은 Test시에 동작이 달라야 하는 <code class="highlighter-rouge">BatchNorm</code>이나, <code class="highlighter-rouge">Dropout</code>을 제어하기 위해서 만들어진 function이다.</li>
  <li><code class="highlighter-rouge">tensorpack_tutorial.ipynb</code>에서는 이 친구를 찾아볼 수 없는데, SimpleTrainer 소스코드를 보니, 자체적으로 안에서 train/test time에 맞춰서 TrainTowerContext라는 것으로 조절하고 있기 때문이었다.</li>
  <li>사용법은 간단하다.
    <blockquote>
      <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training</span>
<span class="k">with</span> <span class="n">TowerContext</span><span class="p">(</span><span class="s">''</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
  <span class="c"># call any tensorpack layer</span>

<span class="n">test</span>
<span class="k">with</span> <span class="n">TowerContext</span><span class="p">(</span><span class="s">'name or empty'</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
  <span class="c"># build the graph again</span>
</code></pre></div>      </div>
    </blockquote>
  </li>
  <li>그래서, 내가 세운 모델을 외부에서 사용하고 싶을 때, 즉, 나만의 Trainer를 새로 정의해서 train/test time때, 다르게 동작을 해야하는 상황이라면, TowerContext를 적절히 써서 분기시켜줘야 한다.</li>
  <li>아래는 Tensorpack Github에서 제공하는 <a href="https://github.com/tensorpack/tensorpack/blob/master/examples/GAN/GAN.py">GANTrainer</a>에서 실제로 TowerContext를 어떻게 설정해주는지 보여주는 예시다.</li>
</ul>

<blockquote>
  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">GANTrainer</span><span class="p">(</span><span class="n">TowerTrainer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="o">..</span>
    <span class="o">...</span>
    
    <span class="c"># Build the graph</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tower_func</span> <span class="o">=</span> <span class="n">TowerFuncWrapper</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">build_graph</span><span class="p">,</span> <span class="n">inputs_desc</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">TowerContext</span><span class="p">(</span><span class="s">''</span><span class="p">,</span> <span class="n">is_training</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tower_func</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="o">.</span><span class="n">get_input_tensors</span><span class="p">())</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_optimizer</span><span class="p">()</span>
    <span class="o">...</span> 
</code></pre></div>  </div>
</blockquote>

<h2 id="thank-you-">Thank you 🙇</h2>

	  ]]></description>
	</item>

	<item>
	  <title>Bias vs. Variance 개념 정리</title>
	  <link>http://localhost:20010/Bias_vs_Variance</link>
		
				
		
				
		
				
						<author>홍규석</author>
				
		
				
		
				
		
				
		
				
		
				
		
				
		
	  <pubDate>2018-01-25T09:00:00+09:00</pubDate>
	  <guid>http://localhost:20010/Bias_vs_Variance</guid>
	  <description><![CDATA[
	     <p>이 글에서 bias와 variance에 대해 살펴보려고 합니다. bias와 variance는 이미 많은 글이나 블로그에서 개념적으로 잘 설명되어 있습니다. 그럼에도 불구하고 다시 정리해보는 이유는 개념적으로 어느정도 이해는 되는데 좀 더 자세하게 보려고 하면, 블로그들의 예제들 간의 연결이 막혀서 헷갈리는 부분이 있어 이 글을 통해 확실히 이해하기 위해서 입니다.</p>

<h2 id="bias-vs-variance의-의미">Bias vs. Variance의 의미</h2>

<p>bias와 variance는 모델의 loss 또는 error를 의미합니다. 우리는 학습 모델의 bias, variance 특성을 구분하는 아래의 그림을 많이 보았습니다. 참고로 아래 그림은 bias-variance trade off를 나타내는 그림이 아닙니다. 아래 그림으로 trade off 관계를 설명하려고 하면 연결이 잘 안될 수 있습니다. (제가 이 글을 통해서 잘 연결 시켜보도록 하겠습니다.)</p>

<p>bias-variance trade off는 잠 시 미뤄두고, bias와 variance의 의미를 파악하는데 집중해 보도록 하겠습니다. 아래 그림은 train data 또는 test data에 대한 결과를 bias와 variance 관점에서 해석하는 그림입니다. 붉은 색 영역은 target, 즉 참 값을 의미하고 파란 점은 추정 값을 의미합니다. 여기서 bias는 참 값들과 추정 값들의 차이(or 평균간의 거리)를 의미하고, variance는 추정 값들의 흩어진 정도를 의미합니다.(이 부분은 뒤에 Mean Square Error 수식을 통해 다시 설명하도록 하겠습니다.) bias와 variance가 loss이므로, 우리는 직관적으로  둘 다 작은 (a) 모델이 가장 좋은 모델인 것을 알 수 있습니다. (b)모델은 추정 값들을 평균한 값은 참 값과 비슷한데(bias가 작은데), 추정 값들의 variance가 커서 loss가 큰 모델입니다.  (c)는 bias가 크고, variance가 작은 모델이고, (d)는 둘 다 큰 모델입니다.</p>

<p><img src="assets/images/posts/2018-01-25-Bias_vs_Variance/3.jpg" alt="high_low_bias_variance" /></p>

<p>위 그림을 이제 train data와 test data 관점에서 살펴보도록 하겠습니다. train data에서는 (a)와 같은 결과 이었는데(train loss가 작았는데), test data를 넣어보니 (b),(c),(d)의 결과가 나왔다고 해 보겠습니다. 3 가지 모두 train data에서는 loss가 작았는데 test data에 적용해 보니 loss가 커졌습니다. 왜 그런 것일까요?</p>

<p>(b),(c),(d)모두 에러가 크지만 서로 다른 유형의 에러를 나타내고 있습니다. 즉, 원인이 다르다는 것을 의미합니다. variance가 큰 (b)모델은 train data에 over-fitting된 것이 원인이고, 이는 너무 train data에 fitting된 모델을 만들어서 test data에서 오차가 발생한 것을 의미합니다. bias가 큰 (c) 모델은 <u>test data</u>를 위한 학습이 덜 된 것이 원인이고, 이는 train data와 test data간의 차이가 너무 커서 train data로만 학습한 모델은 test data를 맞출수가 없는 것입니다. 만일, (c) 그림이 train data에 대한 것이라면 train data에 대해 under-fitting 즉, 학습이 덜 된 모델이라고 할 수 있습니다. (d)는 둘 다의 경우로 생각할 수 있겠습니다.</p>

<p><em>데이터 관점에서 보면 (b)의 경우 train data와 test data의 차이는 variance의 차이라고 할 수 있고,  (c)의 경우 train data와 test data의 차이는 평균의 차이라고도 할 수 있습니다</em>. 학습 모델은 입력 X를 Y로 추정하는 것인데, 입력 X의 분포가 바뀌어 버리면 바뀐만큼의 error가 날 수 밖에 없습니다. 모델이 그렇게 설계되었기 때문입니다. train data와 test data의 차이가 많이 나면 어떻게 해야할까요? 즉, test data에 대해 (c)의 경우 어떻게해야 할까요? 힘들게 설계한 모델은 못쓰게 되는 것일까요? 우선적으로는 test data의 일부를 train set에 포함 시키는 것입니다. 그러나 이러한 방법은 test data에 대해서도 참 값을 labeling 해야하므로 비용도 많이 들고, 실 환경에서는 label이 없는 테스트 데이터가 들어 올 것이기 때문에 고려할 수 없게 됩니다. 이러한 문제를 해결하기 위한 분야가 바로 Domain Adaptation(DA)) 입니다. DA는 test data의 label(참값)없이 data set간의 차이를 줄여주는 네트워크를 기존 모델의 앞단에 추가하여 입력 데이터의 차이를 없애 주는 trick이라고 할 수 있겠습니다. 우리가 잘 학습한 기존 모델에 항상 유사한 입력을 넣어 오차를 줄여주겠다는 것입니다.(DA는 본 내용과 거리가 있으므로 개념적으로만 이해하면 좋을 것 같습니다.)</p>

<h2 id="bias-variance-trade-off">Bias-Variance Trade Off</h2>

<p>위의 train-test set의 관계가 bias-variance trade off로 내용으로 연결됩니다. train data에 너무 잘 맞게 학습시키는 것은 모델 복잡도를 높이는 것을 의미합니다. regression을 예로 생각해 보면 모든 데이터를 연결하는 선을 학습시켰다면 모델 복잡도는 매우 높게 되고 train loss는 ‘0’이 될 것입니다. 그러나, train data에 잘 맞게 만들기 위해 모델 복잡도를 너무 높이면 test data에는 그림1의 (b)처럼 variance가 커져서(bias는 작은데) total loss는 오히려 증가할 수 있습니다. 반대로, 모델 복잡도를 단순하게 가져가면 학습이 덜되서 그림 1의 (c)처럼 bias가 커서(variance는 작은데) total loss는 역시 증가할 수 있습니다. 여기서 말하는 bias와 variance는 서로 상반되어서 이를 <strong>bias-variance trade off</strong> 라고 부릅니다.</p>

<p>왜 그런 것일까요? 왜 모델 복잡도를 높이면 over-fit 될까요?</p>

<p><img src="assets/images/posts/2018-01-25-Bias_vs_Variance/2.jpg" alt="sampling_fluctuation" /></p>

<p>우리가 sub set을 만들 때, 전체(통계에서 말하는 모집단)에서 샘플을 뽑아서 만들텐데, 뽑는 방법, 횟수 등에 따라 위 그림처럼 sub set 간의 변동이 발생하게 됩니다. 다시 말해서 train data와 test data는 이 변동 분 만큼 다를 수 있는 것입니다. train data는 이러한 변동을 포함하고 있는데, train error를 줄이기 위해 모델의 복잡도를 계속 높이면 이 변동 분까지 학습하게 됩니다. 아래 그림의 첫 번째가 이러한 내용을 설명한 것입니다. Linear-&gt;Quadratic-&gt;Spline으로 갈 수록 모델 복잡도가 올라가는 것을 의미하고, Quadratic이 detail한 부분까지 추정하는 것이 위에서의 언급된 샘플링 시의 변동 분까지 학습한 것이라고 할 수 있습니다. 아래의 두번 째 그림처럼 모델 복잡도를 계속 높이면 train loss는 계속해서 감소하지만, sub set간의 변동 분까지 학습하는 시점부터는 test error가 증가하게 됩니다. 이는 train data의 변동 분까지 학습하여 test data에 대한 추정 값의 variance가 증가한 그림1의 (b)와 같은 상황이라고 할 수 있습니다. 그래서 마지막 그림처럼 모델 복잡도가 올라갈 수록 bias는 감소하나 variance는 증가하는 bias-variance trade off 관계가 되는 것입니다. 마지막 그림에서 MSE는 test data의 total loss로 이해하시면 됩니다.</p>

<p>참고: <a href="https://gerardnico.com/wiki/data_mining/bias_trade-off">https://gerardnico.com/wiki/data_mining/bias_trade-off</a></p>

<p><img src="assets/images/posts/2018-01-25-Bias_vs_Variance/4.jpg" alt="img" /></p>

<p>여기서 최적의 모델 복잡도는 위 그림의 세번 째처럼 bias와 variance가 교차하는 부분에서 MSE or total test loss(bias와 variance의 합)가 가장 작은 점의 복잡도를 갖는 것입니다. 즉, 모델의 학습이 train error의 최소가 아닌 test error가 최소가 되도록 해야 한다는 것으로 이해할 수 있습니다. 추가적으로 고려해볼 방법은 처음부터 train set이 갖는 변동을 작게 만드는 것입니다. 이 방법이 바로 n-fold cross validation으로 여러 data set을 만들어 평균적으로 적용시킴으로써 sub set간의 변동을 줄이는 방법이라고 할 수 있습니다.</p>

<p>위 그림에서 total loss를 MSE로 표기했습니다. total loss는 bias와 variance loss를 모두 포함하고 있는 것으로 그렸는데 진짜 그럴까요?</p>

<p>우리가 흔히 사용하는 MSE를 정리하여 다시 구성하면 아래와 같이 variance와 bias의 제곱 텀으로 표현될 수 있다.(sub-set의 변동 분은 제외한 수식입니다.)</p>

<p><img src="assets/images/posts/2018-01-25-Bias_vs_Variance/1.jpg" alt="MSE" /></p>

<p>수식으로 부터 MSE의 variance와 bias의 의미를 다시 살펴보면,</p>

<p><strong>variance</strong>는 <u>추정 값의 평균</u>과 <u>추정 값들</u>간의 차이에 대한 것이고, <strong>bias</strong>는 <u>추정값의 평균</u>과 <u>참 값들</u>간의 차이에 대한 것입니다.  결국, variance는 추정 값들의 흩어진 정도이고, bias는 참 값과 추정 값의 거리를 의미합니다. 이 수식을 보면 <strong><u>variance는 loss를 의미하지만, 참 값과는 관계없이 추정 값들의 흩어진 정도만을 의미</u></strong>하고 있음을 유념해야 합니다.</p>

<p>MSE가 bias와 variance로 구성되어 있고 bias-variance 사이에 trade off 관계인데, 우리가 학습하면 왜 MSE는 작아지고 ‘0’에 가까이 갈까요? 여기서는 trade off 관계가 없는 걸까요?</p>

<p>위의 MSE의 수식을 보면 bias와 variance가 모두 제곱 텀이므로 둘 다 양수 입니다. 즉 MSE가 고정되면 하나가 커지면 하나는 작아지는 trade off 관계에 있습니다. 그런데 왜 학습을 하면 ‘0’에 가까이 수렴할까요?</p>

<p>우리는 학습할 때 bias나 variance의 어느 한쪽을 보고 학습하는 것이 아니라 이 둘을 더한 MSE가 작아지도록 학습을 하기 때문에 최적 값을 알아서 찾아 학습을 하게 됩니다.(아마도 두 값이 거의 같을 때 최적 값이 될 것입니다.) 우리가 주로 고민해야하는 것은 train data들의 b-v trade off가 이니라 train 후 test 할 때의 b-v trade off라고 생각하시면 됩니다. 앞서 언급한 샘플링 시 발생하는 sub set의 변동 들에 대해 고려해야 한다는 것입니다.  train 에서 MSE의 최적 점을 찾았는데 train set과 test set의 차이로 test set에서는 이것이 최적점이 아닐 수 있다는 것입니다. (단, train error가 커서 train error에 대한 분석을 할 때는 train의 b-v에 대해서 고민이 필요할 것 같네요.)</p>

<p>b-v trade off를 한번 더 반복해 보면, 모델 복잡도를 높이면 train data에 대한 bias와 variance는 계속해서 모두 감소합니다(bias+variance이 작아지도록 학습시키므로). 그런데 test data로 평가를 해보면 MSE loss가 어느시점부터 커지는데, 커지는 이유는 test data의 MSE loss 중에서 variance가 다시 커지기 때문이라고 이해하면 좋을 것 같습니다.</p>

<p>그럼 딥러닝은 엄청나게 복잡도 높은 모델을 만드는데 왜 test data도 잘 맞출 수 있다고 할까요? over-fitting 문제가 없을까요?</p>

<p>딥러닝도 똑같이 b-v trade off를 피할 수 없습니다. 딥러닝은 그래서 big 데이터가 전제가 되어야 합니다. big 데이터라는 것은 train data가 많다는 것을 의미하고, 이는 거의 전체 데이터(또는 모집단)와 비슷하다고 할수 있으며, 앞서 말한 sampling 변동이 거의 없다는 것을 전제로 하고 있습니다. 그렇기 때문에 모델 복잡도를 도 높일 수 있는 것입니다. 만일 train data가 적은 상태로 복잡한 딥러닝 모델을 적용하면 over-fitting 문제가 발생할 수 있습니다.  전제가 그렇다는 것이고 모든 경우에 big 데이터가 있는 것은 아니여서 딥러닝에서도 이러한 문제를 없애기 위한 다양한 trick(regularization, dropout, domain adaptation 등)이 존재합니다.</p>

<p>결국, 딥러닝에서의 다양한 trick들은 loss를 줄이기 위한 것이고 , 이 loss는 bias와 variance로 이루어졌다는 것을 기억하면 좋을 것 같습니다. 그리고 그런한 trick들의 효과를 bias-variance 관점에서 생각해보면 다양한 딥러닝 trick들에 대한 더 좋은 이해가 되지 않을까 생각합니다.</p>

<p>이해 안되는 부분이나 틀린 내용있으면 comment 부탁드립니다.</p>

<p>다음에 시간이 되면 ensemble 기법인 bagging과 boosting을 사용했을 때 bias, variance가 어떻게 달라지는지 해석해볼 예정입니다.</p>


	  ]]></description>
	</item>


</channel>
</rss>
