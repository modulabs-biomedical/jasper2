<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.6.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-08-20T16:16:40+09:00</updated><id>http://localhost:4000/</id><title type="html">ë°”ì´ì˜¤ë©”ë””ì»¬ë©@ëª¨ë‘ì˜ì—°êµ¬ì†Œ</title><subtitle>ëª¨ë‘ì˜ì—°êµ¬ì†Œ ë°”ì´ì˜¤ë©”ë””ì»¬ë© ê¸°ìˆ  ë¸”ë¡œê·¸ì…ë‹ˆë‹¤.</subtitle><entry><title type="html">Tensorpack</title><link href="http://localhost:4000/TensorPack" rel="alternate" type="text/html" title="Tensorpack" /><published>2018-08-17T09:00:00+09:00</published><updated>2018-08-17T09:00:00+09:00</updated><id>http://localhost:4000/TensorPack</id><content type="html" xml:base="http://localhost:4000/TensorPack">&lt;h2 id=&quot;tensorpack-êµ¬ì¡°-ì´í•´í•˜ê¸°&quot;&gt;Tensorpack êµ¬ì¡° ì´í•´í•˜ê¸°&lt;/h2&gt;

&lt;h6 id=&quot;modeldescì™€-trainerë¥¼-ì¤‘ì‹¬ìœ¼ë¡œ&quot;&gt;ModelDescì™€ Trainerë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ&lt;/h6&gt;

&lt;h6 id=&quot;peter-cha&quot;&gt;Peter Cha&lt;/h6&gt;

&lt;h4 id=&quot;tensorpackì„-ê³µë¶€í•˜ë©´-&quot;&gt;Tensorpackì„ ê³µë¶€í•˜ë©´, ğŸ˜&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;ìš°ì„  ëª¨ë¥´ëŠ” ê²ƒë“¤ íˆ¬ì„±ì´ë‹¤. ì•Œê³ ë‚˜ë©´ ë„ˆë¬´ ì“°ê¸° í¸í•˜ì§€ë§Œ, ì²˜ìŒ ì ‘í•  ë•ŒëŠ” ë„ˆë¬´ ë§ì´ ì¶”ìƒí™” ëœ APIì— â€˜ì´ê²Œ tensorflowëŠ” ë§ëŠ”ì§€..â€™í•  ì •ë„ë‹ˆê¹Œ.&lt;/li&gt;
  &lt;li&gt;ìš°ì„  ì´ íŠœí† ë¦¬ì–¼ì„ ë³´ê¸° ì „, í•„ìì˜ &lt;a href=&quot;https://github.com/PeterCha90/Tensorflow-Deep-Learning/blob/master/Tensorpack_tutorial.ipynb&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tensorpack_tutorial.ipynb&lt;/code&gt;&lt;/a&gt;ë¥¼ ë¨¼ì € ë³´ê¸¸ ë°”ë€ë‹¤. ëŒ€ëµì ì¸ dataflowëŠ” ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë¶€ë¶„ìœ¼ë¡œ ì´í•´ë¥¼ ë§ˆì³¤ë‹¤ê³  ìƒê°í•˜ê³ , dataflowë¶€ë¶„ì€ ìƒëµí•˜ê³  ì„¤ëª…ì„ ì§„í–‰í•˜ë„ë¡ í•˜ê² ë‹¤.&lt;/li&gt;
  &lt;li&gt;ì´ë²ˆì—ëŠ” Modelì˜ ì„ ì–¸í•˜ê²Œ ë  ë•Œ ìƒì†ë°›ì€ &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ModelDesc&lt;/code&gt;&lt;/strong&gt; classì™€, í•™ìŠµì„ ì‹¤í–‰í•˜ëŠ” Trainerë“¤ì˜ ëª¨íƒœê°€ ë˜ëŠ” &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TowerTrainer&lt;/code&gt;&lt;/strong&gt; ì— ëŒ€í•´ ì•Œì•„ë³´ê³ ì í•œë‹¤.&lt;code class=&quot;highlighter-rouge&quot;&gt;tensorpack_tutorial.ipynb&lt;/code&gt;ì—ì„œ ì„¤ëª…ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì„ í•¨ê»˜ ì°¾ì•„ë³´ë©´ ì´í•´ì— ë„ì›€ì´ ë” ë  ê²ƒ ê°™ë‹¤.&lt;/li&gt;
  &lt;li&gt;ì´ Tutorialì€ Tensorpack &lt;a href=&quot;https://tensorpack.readthedocs.io/modules/train.html?highlight=TowerFuncWrapper&quot;&gt;documentation&lt;/a&gt;ì„ ì°¸ê³ í•´ì„œ ë§Œë“¤ì—ˆë‹¤.
    &lt;hr /&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;1-class-modeldescbase-&quot;&gt;1. Class &lt;code class=&quot;highlighter-rouge&quot;&gt;ModelDescBase&lt;/code&gt; ğŸ˜&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Base class for a model descriptionì´ë‹¤.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ModelDesc&lt;/code&gt;ëŠ” ModelDescBaseë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì¡Œê¸° ë•Œë¬¸ì—, &lt;code class=&quot;highlighter-rouge&quot;&gt;ModelDescBase&lt;/code&gt;ë¥¼ ë¨¼ì € ì„¤ëª…í•œë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;11-build_graphargs&quot;&gt;1.1. build_graph(*args)&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;ëª¨ë“  symbolic graph (&lt;strong&gt;Modelì˜ í˜•íƒœ&lt;/strong&gt;)ë¥¼ Buildí•œë‹¤. ì´ í•¨ìˆ˜ê°€ ë’¤ì—ì„œ ì„¤ëª…í•  &lt;code class=&quot;highlighter-rouge&quot;&gt;TowerTrainer&lt;/code&gt;ì—ì„œ &lt;code class=&quot;highlighter-rouge&quot;&gt;tower function&lt;/code&gt;ì˜ ì¼ë¶€ë¶„ì´ë‹¤.&lt;/li&gt;
  &lt;li&gt;ê·¸ ë‹¤ìŒ ì„¤ëª…í•  &lt;code class=&quot;highlighter-rouge&quot;&gt;inputs()&lt;/code&gt;ì—ì„œ ì •ì˜ëœ input listì— ë§ëŠ” &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.Tensor&lt;/code&gt;ë¥¼ parameterë¡œ ë°›ëŠ”ë‹¤.&lt;/li&gt;
  &lt;li&gt;ì•„ë¬´ê²ƒë„ ë¦¬í„´í•˜ì§€ ì•ŠëŠ”ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;12-inputs&quot;&gt;1.2. inputs()&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Modelì—ì„œ inputìœ¼ë¡œ ë°›ì„ í…ì„œë“¤ì˜ placeholderë“¤ì„ ì •ì˜í•˜ëŠ” í•¨ìˆ˜ë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;í›„ì— &lt;code class=&quot;highlighter-rouge&quot;&gt;InputDesc&lt;/code&gt;ë¡œ ë³€í™˜ë , &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.placeholder&lt;/code&gt;ë“¤ì„ return í•œë‹¤.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-08-17-TensorPack/modeldesc.png&quot; alt=&quot;u-net_fig_2&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;13-get_inputs_desc&quot;&gt;1.3. get_inputs_desc&lt;/h6&gt;

&lt;ul&gt;
  &lt;li&gt;ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´, inputs()ì—ì„œ ì •ì˜ëœ ëª¨ì–‘ëŒ€ë¡œ ìƒê¸´ InputDescë¥¼ listë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ë‹¤.
    &lt;hr /&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-class-modeldesc-&quot;&gt;2. Class &lt;code class=&quot;highlighter-rouge&quot;&gt;ModelDesc&lt;/code&gt; ğŸ˜&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ì£¼ì˜ì‚¬í•­&lt;/strong&gt;: &lt;strong&gt;build_graph()ë¥¼ ê¼­ costë¥¼ returní•˜ë„ë¡&lt;/strong&gt; ì½”ë”©í•´ì•¼ í•œë‹¤.&lt;/li&gt;
  &lt;li&gt;ì•ì—ì„œ ì„¤ëª…í•œ ModelDescBaseë¥¼ ìƒì†ë°›ì€ í„°ë¼, ìœ„ì˜ 3ê°€ì§€ëŠ” í•¨ìˆ˜ëŠ” ë‚´ì¥í•˜ê³  ìˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;21-optimizer&quot;&gt;2.1. optimizer()&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tf.train.Optimizer&lt;/code&gt;ë¥¼ ì—¬ê¸°ì— ì„ ì–¸í•´ì£¼ê³  Returní•˜ê²Œë” í•¨ìˆ˜ë¥¼ ì§œì¤€ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;22-get_optimizer&quot;&gt;2.2. get_optimizer()&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;optimizer()ë¥¼ í˜¸ì¶œí•˜ë©´, ê³„ì† ìƒˆë¡œ optimizerë¥¼ ë§Œë“¤ì–´ì„œ ìƒì„±í•˜ëŠ”ë°, ì´ í•¨ìˆ˜ë¥¼ ì“°ë©´ ì´ë¯¸ optimizer()ë¥¼ í†µí•´ ìƒê¸´ optimizerë¥¼ ê¸°ë¡í•´ ë†“ì•˜ë‹¤ê°€ ë°˜í™˜ì‹œì¼œì¤€ë‹¤.
    &lt;hr /&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-class-towertrainer-&quot;&gt;3. Class &lt;code class=&quot;highlighter-rouge&quot;&gt;TowerTrainer&lt;/code&gt; ğŸ˜¶&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Tensorpackì—ì„œëŠ”, ìš°ë¦¬ê°€ í”íˆ ë§í•˜ëŠ” Modelì„ ê³„ì† Towerë¼ê³  ì§€ì¹­í•œë‹¤.(ì™œ ê·¸ëŸ°ì§€ ëª¨ë¥´ê² ë‹¤. ğŸ˜¶)&lt;/li&gt;
  &lt;li&gt;ê·¸ë˜ì„œ ì•„ë˜ì—ì„œ ë‚˜ì˜¤ëŠ” &lt;code class=&quot;highlighter-rouge&quot;&gt;TowerTrainer&lt;/code&gt;ëŠ” ë§Œë“  ëª¨ë¸ì„ í•™ìŠµì„ ì‹œí‚¤ëŠ” &lt;strong&gt;Trainer&lt;/strong&gt;ê³ , ê·¸ íŠ¸ë ˆì´ë„ˆê°€ ì–´ë–¤ íŠ¹ì§•ë“¤ì„ ê°€ì§„ í•¨ìˆ˜ë“¤ì„ ë“¤ê³  ë‹¤ë‹ˆëŠ”ì§€ ìƒê°í•˜ë©´ ì´í•´ê°€ ì‰½ë‹¤.&lt;/li&gt;
  &lt;li&gt;ê¸°ë³¸ì ìœ¼ë¡œ Tensorpackì— ë‚˜ì˜¤ëŠ” ëª¨ë“  Trainerë“¤ì€ &lt;code class=&quot;highlighter-rouge&quot;&gt;TowerTrainer&lt;/code&gt;ì˜ subclassë‹¤ ì´ ê°œë…ì´ ê·¸ë˜ì„œ ê¶ê·¹ì ìœ¼ë¡œëŠ” ëª¨ë“  neural-network trainingì„ ê°€ëŠ¥í•˜ê²Œ í•´ì¤€ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;31-get_predictorinput_names-output_names-device0&quot;&gt;3.1. &lt;code class=&quot;highlighter-rouge&quot;&gt;get_predictor&lt;/code&gt;(input_names, output_names, device=0)&lt;/h6&gt;

&lt;blockquote&gt;
  &lt;p&gt;Returns a callable predictor built under &lt;code class=&quot;highlighter-rouge&quot;&gt;TowerContext(is_training=False)&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;ì´ í•¨ìˆ˜ê°€ í˜¸ì¶œë˜ë©´, ê°€ì§€ê³  ìˆëŠ” TowerContext(ëª¨ë¸ì˜ Train or Test ì—¬ë¶€)ë¥¼ &lt;u&gt;training modeê°€ ì•„ë‹Œ ìƒíƒœ(is_training=False, ì¦‰=Test ëª¨ë“œ)&lt;/u&gt;ë¡œ ëŒë ¤ì¤€ë‹¤. ê·¸ëŸ¬ë‹ˆê¹Œ &lt;strong&gt;Test dataë¡œ ì‹œí—˜í•  ë•Œë§Œ ë¶€ë¥´ëŠ” í•¨ìˆ˜&lt;/strong&gt;. ê·¸ë˜ì„œ ì´ë¦„ë„ predictor.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Parameters&lt;/code&gt;&lt;/strong&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;input_names&lt;/code&gt; &lt;strong&gt;(list)&lt;/strong&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;output_names&lt;/code&gt; &lt;strong&gt;(list)&lt;/strong&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;device&lt;/code&gt; &lt;strong&gt;(int)&lt;/strong&gt; â€“ build the predictor on device â€˜/gpu:{device}â€™ or use -1 for â€˜/cpu:0â€™.&lt;/li&gt;
  &lt;li&gt;íŒŒë¼ë¯¸í„°ë¡œ ë“¤ì–´ê°€ëŠ” input, outputì´ë¦„ì€ ëª¨ë¸ ì•ˆì—ì„œ ì„ ì–¸ëœ ì´ë¦„ì´ ì•„ë‹ˆë©´ ì•ˆ ëŒì•„ê°€ë‹ˆê¹Œ ì¡°ì‹¬.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;32-inputs_desc&quot;&gt;3.2. inputs_desc&lt;/h6&gt;

&lt;blockquote&gt;
  &lt;p&gt;Returns â€“ list[InputDesc]: metainfo about the inputs to the tower.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;ë§ ê·¸ëŒ€ë¡œ, ëª¨ë¸ì— ë“¤ì–´ê°ˆ Inputì˜ í¬ê¸°ì™€ ê°™ì€ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” listë¥¼ ë°˜í™˜í•´ì¤€ë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;33-tower_func&quot;&gt;3.3. tower_func&lt;/h6&gt;

&lt;blockquote&gt;
  &lt;p&gt;Build Model.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;ì´ ì¹œêµ¬ê°€ ì‹¤ì œ &lt;strong&gt;ëª¨ë¸ì„ ì •ì˜í•˜ê³ , Build&lt;/strong&gt;í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë¥¼ ì„¸íŒ…í•˜ëŠ” ë¶€ë¶„!&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ModelDesc&lt;/code&gt;&lt;/strong&gt; interfaceë¡œ ì •ì˜ëœ modelì„ trainerë¡œ ëŒë ¤ì•¼ í•˜ëŠ” ìƒí™©ì´ ìì£¼ ë°œìƒí•  ìˆ˜ ìˆëŠ”ë°, ì´ ë•Œ, &lt;u&gt;ModelDescì—ì„œ ì„ ì–¸ëœ **build_graph í•¨ìˆ˜**ê°€ ì´ ì—­í• ì„ ëŒ€ì‹ &lt;/u&gt;í•´ ì¤„ ìˆ˜ ìˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;34-towers&quot;&gt;3.4. towers&lt;/h6&gt;
&lt;blockquote&gt;
  &lt;p&gt;Returns â€“ a TowerTensorHandles object, to
access the tower handles by either indices or names.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ëª¨ë¸ ë° Train ì „ë°˜ì— ê±¸ì³ ê´€ë ¨ëœ ë³€ìˆ˜ë“¤ì— ì ‘ê·¼í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•œë‹¤! ê·¸ë˜ì„œ ì´ í•¨ìˆ˜ëŠ” Transfer learningì„ í•  ë•Œ ìœ ìš©í•  ê±° ê°™ë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ì´ë¯¸ &lt;strong&gt;ëª¨ë¸ ê·¸ë˜í”„ê°€ Set upì´ ëë‚œ ë’¤ì—ë§Œ&lt;/strong&gt; ì´ í•¨ìˆ˜ëŠ” í˜¸ì¶œë  ìˆ˜ ìˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ê°ê°ì˜ &lt;code class=&quot;highlighter-rouge&quot;&gt;layer&lt;/code&gt;ì™€ &lt;code class=&quot;highlighter-rouge&quot;&gt;attributes&lt;/code&gt;ì— ì´ &lt;code class=&quot;highlighter-rouge&quot;&gt;towers&lt;/code&gt;í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ë©´ ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ ëœë‹¤! ì•„ë˜ëŠ” ì˜ˆì‹œ.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-08-17-TensorPack/3-4.png&quot; alt=&quot;u-net_fig_2&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;â€‹&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-class-trainer-&quot;&gt;4. Class &lt;code class=&quot;highlighter-rouge&quot;&gt;Trainer&lt;/code&gt; ğŸ™„&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;Base class for a trainer.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;ë¶„ëª…íˆ ìœ„ì—ì„œ ê¸ˆë°©,
    &lt;blockquote&gt;
      &lt;p&gt;â€œê¸°ë³¸ì ìœ¼ë¡œ Tensorpackì— ë‚˜ì˜¤ëŠ” ëª¨ë“  Trainerë“¤ì€ &lt;code class=&quot;highlighter-rouge&quot;&gt;TowerTrainer&lt;/code&gt;ì˜ subclassë‹¤â€&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ë¼ê³  í–ˆëŠ”ë°, ì´ &lt;code class=&quot;highlighter-rouge&quot;&gt;TowerTrainerê°€ ìƒì†ì„ ë°›ëŠ” class&lt;/code&gt;ê°€ ìˆì—ˆìœ¼ë‹ˆ, ì´ë¦„í•˜ì—¬ TowerTrainerë³´ë‹¤ ë” ë‹¨ìˆœí•œ &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Trainer&lt;/code&gt;&lt;/strong&gt; ë‹¤.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ë‹¤ë¥¸ TowerTrainerë¥¼ ìƒì† ë°›ì€ Trainerë“¤ì„ ì‚¬ìš©í•  ë•Œ, ì¢…ì¢… TowerTrainerì—ì„œ ë³¸ ì  ì—†ëŠ” ì¹œêµ¬ë“¤ì´ ë‚˜íƒ€ë‚˜ëŠ”ë°, ê·¸ ì¹œêµ¬ë“¤ì´ Trainerì˜ ê²ƒì¸ ê²½ìš°ê°€ ìˆë‹¤.&lt;/li&gt;
  &lt;li&gt;í•˜ì§€ë§Œ, Trainer ê³ ìœ  í•¨ìˆ˜ë‚˜ ìš”ì†Œì— ì§ì ‘ì ìœ¼ë¡œ ì ‘ê·¼í•  ì¼ì´ ë³„ë¡œ ì—†ì–´ì„œ ì•„ë˜ì˜ 3ê°€ì§€ ì •ë„ë§Œ ì•Œê³  ìˆìœ¼ë©´ ë  ê²ƒ ê°™ë‹¤. ë‚˜ë¨¸ì§€ëŠ” &lt;a href=&quot;https://tensorpack.readthedocs.io/modules/train.html?highlight=register_callback#tensorpack.train.Trainer&quot;&gt;ë¬¸ì„œ&lt;/a&gt;ë¥¼ ì°¸ê³ í•˜ì.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;ì•„ë˜ 1, 2ë²ˆì˜ max_epochê³¼, steps_per_epochì€ &lt;code class=&quot;highlighter-rouge&quot;&gt;TrainConfig&lt;/code&gt;ì—ì„œ ìì£¼ ë§Œë‚˜ëŠ” í‚¤ì›Œë“œë“¤ì¸ë°, ì´ ì¹œêµ¬ë“¤ì´ Trainerì˜ ìš”ì†Œì˜€ë‹¤.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h6 id=&quot;41-max_epoch&quot;&gt;4.1. max_epoch&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;Epochì€ ëª‡ ë²ˆ ëŒë¦´ ê²ƒì¸ì§€&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;42-steps_per_epoch&quot;&gt;4.2. steps_per_epoch&lt;/h6&gt;
&lt;ul&gt;
  &lt;li&gt;í•œ ì—í­ë‹¹ stepsì€ ì´ ëª‡ ë²ˆì¸ì§€.
&lt;img src=&quot;../assets/images/posts/2018-08-17-TensorPack/sample.png&quot; alt=&quot;u-net_fig_2&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;43-register_callbackcb&quot;&gt;4.3. register_callback(cb)&lt;/h6&gt;

&lt;blockquote&gt;
  &lt;p&gt;Register callbacks to the trainer. It can only be called before Trainer.train().&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;u&gt;Trainerê°€ ëª¨ë¸ì„ ëŒë¦´ ë•Œë§ˆë‹¤(epochì´ ì§„í–‰ ë¨ì— ë”°ë¼), ìˆ˜í–‰í•˜ê²Œ ë  ë¶€ê°€ì ì¸ ê¸°ëŠ¥&lt;/u&gt;ë“¤ì„ Tensorpackì—ì„œëŠ” &lt;strong&gt;callback&lt;/strong&gt;ì´ë¼ê³  ë¶€ë¥´ê³ , ëŒ€í‘œì ì¸ callbackìœ¼ë¡œ &lt;strong&gt;ModelSaver()&lt;/strong&gt; ê°€ ìˆë‹¤.&lt;/li&gt;
  &lt;li&gt;ì´ Callbackì„ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•˜ì—¬ Trainer Objectì— ì„¸íŒ…í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ë‹¤. ì£¼ë¡œ ëª¨ë¸ì„ íŠœë‹í•  ë•Œ, ì„¤ì •í•˜ë©´ì„œ ì¢…ì¢… ì“°ëŠ” ê²ƒì„ ì½”ë“œ ìƒì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;5-towercontext-&quot;&gt;5. TowerContext ğŸ˜›&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TowerContext&lt;/code&gt;&lt;/strong&gt; ëŠ” Trainingê³¼ Validation í˜¹ì€ Testì‹œì— ë™ì‘ì´ ë‹¬ë¼ì•¼ í•˜ëŠ” &lt;code class=&quot;highlighter-rouge&quot;&gt;BatchNorm&lt;/code&gt;ì´ë‚˜, &lt;code class=&quot;highlighter-rouge&quot;&gt;Dropout&lt;/code&gt;ì„ ì œì–´í•˜ê¸° ìœ„í•´ì„œ ë§Œë“¤ì–´ì§„ functionì´ë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tensorpack_tutorial.ipynb&lt;/code&gt;ì—ì„œëŠ” ì´ ì¹œêµ¬ë¥¼ ì°¾ì•„ë³¼ ìˆ˜ ì—†ëŠ”ë°, SimpleTrainer ì†ŒìŠ¤ì½”ë“œë¥¼ ë³´ë‹ˆ, ìì²´ì ìœ¼ë¡œ ì•ˆì—ì„œ train/test timeì— ë§ì¶°ì„œ TrainTowerContextë¼ëŠ” ê²ƒìœ¼ë¡œ ì¡°ì ˆí•˜ê³  ìˆê¸° ë•Œë¬¸ì´ì—ˆë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ì‚¬ìš©ë²•ì€ ê°„ë‹¨í•˜ë‹¤.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-08-17-TensorPack/5-1.png&quot; alt=&quot;u-net_fig_2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;â€‹&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;ê·¸ë˜ì„œ, ë‚´ê°€ ì„¸ìš´ ëª¨ë¸ì„ ì™¸ë¶€ì—ì„œ ì‚¬ìš©í•˜ê³  ì‹¶ì„ ë•Œ, ì¦‰, ë‚˜ë§Œì˜ Trainerë¥¼ ìƒˆë¡œ ì •ì˜í•´ì„œ train/test timeë•Œ, ë‹¤ë¥´ê²Œ ë™ì‘ì„ í•´ì•¼í•˜ëŠ” ìƒí™©ì´ë¼ë©´, TowerContextë¥¼ ì ì ˆíˆ ì¨ì„œ ë¶„ê¸°ì‹œì¼œì¤˜ì•¼ í•œë‹¤.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ì•„ë˜ëŠ” Tensorpack Githubì—ì„œ ì œê³µí•˜ëŠ” &lt;a href=&quot;https://github.com/tensorpack/tensorpack/blob/master/examples/GAN/GAN.py&quot;&gt;GANTrainer&lt;/a&gt;ì—ì„œ ì‹¤ì œë¡œ TowerContextë¥¼ ì–´ë–»ê²Œ ì„¤ì •í•´ì£¼ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ì˜ˆì‹œë‹¤.&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-08-17-TensorPack/5-2.png&quot; alt=&quot;u-net_fig_2&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;â€‹&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;thank-you-&quot;&gt;Thank you ğŸ™‡&lt;/h2&gt;</content><author><name>ì°¨ì˜ˆì†”</name></author><category term="ê°œë… ì •ë¦¬" /><summary type="html">Tensorpack êµ¬ì¡° ì´í•´í•˜ê¸°</summary></entry><entry><title type="html">FusionNet</title><link href="http://localhost:4000/FusionNet" rel="alternate" type="text/html" title="FusionNet" /><published>2018-05-04T09:00:00+09:00</published><updated>2018-05-04T09:00:00+09:00</updated><id>http://localhost:4000/FusionNet</id><content type="html" xml:base="http://localhost:4000/FusionNet">&lt;h1 id=&quot;fusionnet&quot;&gt;&lt;strong&gt;FusionNet&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;FusionNetì€ U-Netì²˜ëŸ¼ Semantic Segmentationì— í™œìš© í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ë¦„ì´ FusionNetì¸ ì´ìœ ëŠ” ì•„ë§ˆë„ Encoderì— ìˆëŠ” Layerë¥¼ ê°€ì ¸ì™€ Decoderì— ê²°í•©(Fusion)í•˜ëŠ” ë°©ë²•ì´ ì´ ëª¨ë¸ì— ê°€ì¥ íŠ¹ì§•ì ì¸ ë¶€ë¶„ì´ê¸° ë•Œë¬¸ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;U-Netê³¼ ìœ ì‚¬í•œ ë¶€ë¶„ì´ ë§ê¸° ë•Œë¬¸ì— ë¸”ë¡œê·¸ì— U-Netê¸€ì„ ì½ìœ¼ì‹œë©´ ë§ì€ ë„ì›€ì´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤. 
&lt;a href=&quot;https://modulabs-biomedical.github.io/U_Net&quot;&gt;U-Net (by ê°•ì€ìˆ™)&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;fusionnet-ì´ë€&quot;&gt;FusionNet ì´ë€?&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;FusionNet&lt;/strong&gt;ì€ Connectomics(ë‡Œì‹ ê²½ ì—°ê²°ì§€ë„ë¥¼ ì‘ì„±í•˜ê³  ë¶„ì„í•˜ëŠ” ì‹ ê²½ê³¼í•™ì˜ ì¼ì¢…) ë°ì´í„°ì—ì„œ ì‹ ê²½êµ¬ì¡°ë¥¼ Segmentation í•  ëª©ì ìœ¼ë¡œ ë§Œë“  ë”¥ëŸ¬ë‹ ëª¨ë¸ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë…¼ë¬¸ë°œí‘œì¼(2016.12.26) ê¸°ì¤€ì—ì„œ ìµœì‹ ì˜ ê¸°ìˆ ì¸ Semantic Segmentationê³¼ Residual Neural Networksë¥¼ ì‚¬ìš© í•œ ëª¨ë¸ì´ë¼ê³  í•˜ë„¤ìš”.&lt;/p&gt;

&lt;p&gt;ì´ ë…¼ë¬¸ì—ì„œëŠ” FusionNetì„ Electron Microscopy (EM) ì´ë¯¸ì§€ì—ì„œ Cell Membraneê³¼ Cell Bodyì˜ Segmentationì— ì ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;ëª¨ë¸ì˜-íŠ¹ì§•&quot;&gt;ëª¨ë¸ì˜ íŠ¹ì§•&lt;/h3&gt;

&lt;p&gt;ì´ì „ì— connectomicsì—ì„œ automatic image segmentationì„ í•  ë•Œ ë³´í†µ &lt;strong&gt;CNN(Convolutional Neural Network)&lt;/strong&gt;ì— ê¸°ë°˜ í•œ &lt;strong&gt;patch-based pixel-wise classification&lt;/strong&gt;ì„ ì‚¬ìš©í–ˆëŠ”ë° EM ë°ì´í„°ê°€ ìš©ëŸ‰ì´ ìƒë‹¹íˆ í¬ê¸° ë•Œë¬¸ì— ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë¹„ìš©ì´ ë§ì´ ë“¤ì–´ê°„ë‹¤ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;( ì—¬ê¸°ì„œ ë¹„ìš©ì´ë€ ë”¥ëŸ¬ë‹ì„ í•˜ê¸° ìœ„í•œ í•˜ë“œì›¨ì–´ êµ¬ì…, ì „ê¸° ì‚¬ìš©, ì‹œê°„ ë“±ì„ ë§í•©ë‹ˆë‹¤. )&lt;/p&gt;

&lt;p&gt;Encoding, Decodingì„ ì‚¬ìš©í•œ &lt;strong&gt;FCN(fully Convolution Neural Network)&lt;/strong&gt;ê³„ì—´ì˜ ëª¨ë¸ì˜ ê²½ìš° ì—°ì‚°ëŸ‰ì„ ì¤„ì¼ ìˆ˜ ìˆì–´ ë¹„ìš©ì„ ì ˆê° í•  ìˆ˜ ìˆëŠ”ë° ì´ê²ƒì— ëŒ€í‘œì ì¸ ëª¨ë¸ì´ &lt;strong&gt;U-Net&lt;/strong&gt;ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;í•˜ì§€ë§Œ &lt;strong&gt;U-Net&lt;/strong&gt;ì˜ ë°©ë²•ì´ ë°ì´í„°ë¡œë¶€í„° ë‹¤ì¤‘ì˜ ë§¥ë½ ì •ë³´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆì§€ë§Œ &lt;strong&gt;Gradient Vanising&lt;/strong&gt; ë¬¸ì œê°€ ë°œìƒí•˜ê¸° ë•Œë¬¸ì— ê¹Šì€ ë„¤íŠ¸ì›Œí¬ë¥¼ ë§Œë“œëŠ” ê²ƒì€ ì œí•œì ì´ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;FusionNet&lt;/strong&gt;ì€ &lt;strong&gt;residual layers&lt;/strong&gt;ì™€ &lt;strong&gt;summation-based skip connection&lt;/strong&gt;ì„ ì‚¬ìš©í•˜ì—¬ &lt;strong&gt;U-Net&lt;/strong&gt;ì˜ ë‹¨ì ì„ ë³´ì™„í•œ ëª¨ë¸ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;residual layer&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ì´ì „ì— ê³„ì‚°ëœ ê°’ì„ ë’·ë¶€ë¶„ì—ë„ ì—°ê²°ì‹œì¼œì„œ ëª¨ë¸ì´ ê¹Šì–´ì ¸ë„ ê°’ì„ ìŠì–´ë²„ë¦¬ì§€ ì•Šê²Œ í•´ì£¼ëŠ” ì—­í• ì„ í•¨ (vanishing gradient ë¬¸ì œ í•´ê²°)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;summation-based skip connections&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ì¸µì„ ê±´ë„ˆë„ì›Œì„œ ì—°ê²°, ê±´ë„ˆë„ì›Œ ë„˜ì–´ì˜¨ ì¸µê³¼ ì´ì „ì˜ ì¸µì„ ë”í•´ì„œ(í•©ê³„ì‚°) ë’¤ì— ì¸µìœ¼ë¡œ ë„˜ê¹€&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5 id=&quot;pytorch-code-ì˜ˆì‹œ-summation-based-skip-connections&quot;&gt;Pytorch Code ì˜ˆì‹œ (summation-based skip connections)&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-05-04-Fusion_Net/fusion-net_1.png&quot; alt=&quot;fusion-net_1&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;u-netê³¼-ë¹„êµí•˜ì—¬-ê°€ì¥-íŠ¹ì§•ì ì¸-ì°¨ì´&quot;&gt;U-Netê³¼ ë¹„êµí•˜ì—¬ ê°€ì¥ íŠ¹ì§•ì ì¸ ì°¨ì´&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;U-net&lt;/strong&gt;ì—ì„œëŠ” ê¸´ skip connectionì„ í†µí•´ feature mapì„ &lt;strong&gt;ì´ì–´ ë¶™ì„ (Concatenating)&lt;/strong&gt; 
&lt;strong&gt;FusionNet&lt;/strong&gt;ì—ì„œëŠ” ê¸´ skip connectionì„ í†µí•´ feature mapì˜ &lt;strong&gt;ê°’ì„ ë”í•¨&lt;/strong&gt; + ì§§ì€ skip connectionë„ encoding, decodingì˜ ê° stepì—ì„œ ì‚¬ìš©&lt;/p&gt;

&lt;p&gt;ì´ ë°©ë²•ì´ ì‹¤ì œë¡œ ì¢‹ì€ í¼í¬ë¨¼ìŠ¤ë¥¼ ë³´ì—¬ì„œ &lt;strong&gt;ISBI 2012 EM segmentation challenge&lt;/strong&gt;ì—ì„œ &lt;strong&gt;1ë“±&lt;/strong&gt; í–ˆë‹¤ê³  í•©ë‹ˆë‹¤.
(ë¬¼ë¡  FusionNetì´ 100% ê¸°ì—¬í–ˆë‹¤ê³  ê¹Œì§€ëŠ” ë³¼ ìˆ˜ ì—†ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.)&lt;/p&gt;

&lt;p&gt;OverFitting í•´ê²°ì„ ìœ„í•œ &lt;strong&gt;Data enrichment&lt;/strong&gt; (ì´ë¯¸ì§€ ë°ì´í„°ì— ë‹¤ì–‘í•œ ë³€í˜•ì„ ê°€í•˜ê±°ë‚˜ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ëŠ” ë“±ì˜ ë°©ë²•ì„ ì‚¬ìš©)ë¥¼ ì‚¬ìš© í•œ ê²ƒë„ ì¢‹ì€ í¼í¬ë¨¼ìŠ¤ë¥¼ ë‚´ëŠ”ë° ë„ì›€ì´ ë˜ì—ˆì„ ê²ƒ ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-05-04-Fusion_Net/fusion-net_2.png&quot; alt=&quot;fusion-net_2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì •ë§ U-Netë³´ë‹¤ ê²°ê³¼ê°€ ì¢‹ë„¤ìš”!!!&lt;/p&gt;

&lt;h3 id=&quot;ëª¨ë¸-ì•„í‚¤í…ì²˜&quot;&gt;ëª¨ë¸ ì•„í‚¤í…ì²˜&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-05-04-Fusion_Net/fusion-net_3.png&quot; alt=&quot;fusion-net_3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Encoding Path&lt;/strong&gt;	-&amp;gt;	640X640ë¶€í„° 40X40 ê¹Œì§€ the features of interestë¥¼ ê²€ì¶œ&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Decoding Path&lt;/strong&gt;	-&amp;gt;	40X40ë¶€í„° 640X640ê¹Œì§€ synthesisë¥¼ ì˜ˆì¸¡&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ë…¹ìƒ‰ ë¸”ë¡&lt;/strong&gt;	-&amp;gt;	regular convolutional layer, ReLu í™œì„±í•¨ìˆ˜, batch normalizationìœ¼ë¡œ êµ¬ì„±&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ë³´ë¼ìƒ‰ ë¸”ë¡&lt;/strong&gt;	-&amp;gt;	3ê°œì˜ convolutional blockìœ¼ë¡œ êµ¬ì„±ë˜ëŠ”ë° ë§ˆì§€ë§‰ ë¸”ë¡3ì—ëŠ” ë¸”ë¡1ì´ ë¸”ë¡2ì™€ skipí•´ì„œ ë”í•´ì§„ residual layerê°€ ì—°ê²° ë¨&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;íŒŒë€ìƒ‰ ë¸”ë¡&lt;/strong&gt;	-&amp;gt;	maxpooling layerë¡œì¨ encoding pathì—ì„œ feature ì••ì¶•ì„ ìœ„í•œ downsamplingì„ í•˜ê¸° ìœ„í•´ ì‚¬ìš©&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ë¹¨ê°„ìƒ‰ ë¸”ë¡&lt;/strong&gt;	-&amp;gt;	deconvolutional layerë¡œ decoding pathì—ì„œ interpolationì„ ì‚¬ìš©í•œ upsamplingì„ í•˜ê¸° ìœ„í•´ ì‚¬ìš©&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-05-04-Fusion_Net/fusion-net_4.png&quot; alt=&quot;fusion-net_4&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;ì°¸ê³ ìë£Œ&quot;&gt;ì°¸ê³ ìë£Œ&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/ftp/arxiv/papers/1612/1612.05360.pdf&quot;&gt;FusionNet : A deep fully residual convolutional neural network for image segmentation in connectomics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ì´ìƒìœ¼ë¡œ FusionNetì— ëŒ€í•œ ê¸€ì„ ë§ˆì¹©ë‹ˆë‹¤. ìˆ˜ì •í•´ì•¼ í•  ë‚´ìš©ì´ ìˆë‹¤ë©´ ê¼­ ë§ì”€ ë¶€íƒë“œë¦½ë‹ˆë‹¤.
ë¶€ì¡±í•œ ê¸€ì´ì§€ë§Œ ëê¹Œì§€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!!!&lt;/p&gt;</content><author><name>ê¹€ê²½ëª¨</name></author><category term="ë…¼ë¬¸ ë¦¬ë·°" /><summary type="html">FusionNet FusionNetì€ U-Netì²˜ëŸ¼ Semantic Segmentationì— í™œìš© í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. ì´ë¦„ì´ FusionNetì¸ ì´ìœ ëŠ” ì•„ë§ˆë„ Encoderì— ìˆëŠ” Layerë¥¼ ê°€ì ¸ì™€ Decoderì— ê²°í•©(Fusion)í•˜ëŠ” ë°©ë²•ì´ ì´ ëª¨ë¸ì— ê°€ì¥ íŠ¹ì§•ì ì¸ ë¶€ë¶„ì´ê¸° ë•Œë¬¸ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤. U-Netê³¼ ìœ ì‚¬í•œ ë¶€ë¶„ì´ ë§ê¸° ë•Œë¬¸ì— ë¸”ë¡œê·¸ì— U-Netê¸€ì„ ì½ìœ¼ì‹œë©´ ë§ì€ ë„ì›€ì´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤. U-Net (by ê°•ì€ìˆ™) FusionNet ì´ë€? FusionNetì€ Connectomics(ë‡Œì‹ ê²½ ì—°ê²°ì§€ë„ë¥¼ ì‘ì„±í•˜ê³  ë¶„ì„í•˜ëŠ” ì‹ ê²½ê³¼í•™ì˜ ì¼ì¢…) ë°ì´í„°ì—ì„œ ì‹ ê²½êµ¬ì¡°ë¥¼ Segmentation í•  ëª©ì ìœ¼ë¡œ ë§Œë“  ë”¥ëŸ¬ë‹ ëª¨ë¸ì…ë‹ˆë‹¤. ë…¼ë¬¸ë°œí‘œì¼(2016.12.26) ê¸°ì¤€ì—ì„œ ìµœì‹ ì˜ ê¸°ìˆ ì¸ Semantic Segmentationê³¼ Residual Neural Networksë¥¼ ì‚¬ìš© í•œ ëª¨ë¸ì´ë¼ê³  í•˜ë„¤ìš”. ì´ ë…¼ë¬¸ì—ì„œëŠ” FusionNetì„ Electron Microscopy (EM) ì´ë¯¸ì§€ì—ì„œ Cell Membraneê³¼ Cell Bodyì˜ Segmentationì— ì ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. ëª¨ë¸ì˜ íŠ¹ì§• ì´ì „ì— connectomicsì—ì„œ automatic image segmentationì„ í•  ë•Œ ë³´í†µ CNN(Convolutional Neural Network)ì— ê¸°ë°˜ í•œ patch-based pixel-wise classificationì„ ì‚¬ìš©í–ˆëŠ”ë° EM ë°ì´í„°ê°€ ìš©ëŸ‰ì´ ìƒë‹¹íˆ í¬ê¸° ë•Œë¬¸ì— ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë¹„ìš©ì´ ë§ì´ ë“¤ì–´ê°„ë‹¤ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ( ì—¬ê¸°ì„œ ë¹„ìš©ì´ë€ ë”¥ëŸ¬ë‹ì„ í•˜ê¸° ìœ„í•œ í•˜ë“œì›¨ì–´ êµ¬ì…, ì „ê¸° ì‚¬ìš©, ì‹œê°„ ë“±ì„ ë§í•©ë‹ˆë‹¤. ) Encoding, Decodingì„ ì‚¬ìš©í•œ FCN(fully Convolution Neural Network)ê³„ì—´ì˜ ëª¨ë¸ì˜ ê²½ìš° ì—°ì‚°ëŸ‰ì„ ì¤„ì¼ ìˆ˜ ìˆì–´ ë¹„ìš©ì„ ì ˆê° í•  ìˆ˜ ìˆëŠ”ë° ì´ê²ƒì— ëŒ€í‘œì ì¸ ëª¨ë¸ì´ U-Netì…ë‹ˆë‹¤. í•˜ì§€ë§Œ U-Netì˜ ë°©ë²•ì´ ë°ì´í„°ë¡œë¶€í„° ë‹¤ì¤‘ì˜ ë§¥ë½ ì •ë³´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆì§€ë§Œ Gradient Vanising ë¬¸ì œê°€ ë°œìƒí•˜ê¸° ë•Œë¬¸ì— ê¹Šì€ ë„¤íŠ¸ì›Œí¬ë¥¼ ë§Œë“œëŠ” ê²ƒì€ ì œí•œì ì´ì—ˆìŠµë‹ˆë‹¤. FusionNetì€ residual layersì™€ summation-based skip connectionì„ ì‚¬ìš©í•˜ì—¬ U-Netì˜ ë‹¨ì ì„ ë³´ì™„í•œ ëª¨ë¸ì…ë‹ˆë‹¤. residual layer ì´ì „ì— ê³„ì‚°ëœ ê°’ì„ ë’·ë¶€ë¶„ì—ë„ ì—°ê²°ì‹œì¼œì„œ ëª¨ë¸ì´ ê¹Šì–´ì ¸ë„ ê°’ì„ ìŠì–´ë²„ë¦¬ì§€ ì•Šê²Œ í•´ì£¼ëŠ” ì—­í• ì„ í•¨ (vanishing gradient ë¬¸ì œ í•´ê²°) summation-based skip connections ì¸µì„ ê±´ë„ˆë„ì›Œì„œ ì—°ê²°, ê±´ë„ˆë„ì›Œ ë„˜ì–´ì˜¨ ì¸µê³¼ ì´ì „ì˜ ì¸µì„ ë”í•´ì„œ(í•©ê³„ì‚°) ë’¤ì— ì¸µìœ¼ë¡œ ë„˜ê¹€ Pytorch Code ì˜ˆì‹œ (summation-based skip connections) U-Netê³¼ ë¹„êµí•˜ì—¬ ê°€ì¥ íŠ¹ì§•ì ì¸ ì°¨ì´ U-netì—ì„œëŠ” ê¸´ skip connectionì„ í†µí•´ feature mapì„ ì´ì–´ ë¶™ì„ (Concatenating) FusionNetì—ì„œëŠ” ê¸´ skip connectionì„ í†µí•´ feature mapì˜ ê°’ì„ ë”í•¨ + ì§§ì€ skip connectionë„ encoding, decodingì˜ ê° stepì—ì„œ ì‚¬ìš© ì´ ë°©ë²•ì´ ì‹¤ì œë¡œ ì¢‹ì€ í¼í¬ë¨¼ìŠ¤ë¥¼ ë³´ì—¬ì„œ ISBI 2012 EM segmentation challengeì—ì„œ 1ë“± í–ˆë‹¤ê³  í•©ë‹ˆë‹¤. (ë¬¼ë¡  FusionNetì´ 100% ê¸°ì—¬í–ˆë‹¤ê³  ê¹Œì§€ëŠ” ë³¼ ìˆ˜ ì—†ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.) OverFitting í•´ê²°ì„ ìœ„í•œ Data enrichment (ì´ë¯¸ì§€ ë°ì´í„°ì— ë‹¤ì–‘í•œ ë³€í˜•ì„ ê°€í•˜ê±°ë‚˜ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ëŠ” ë“±ì˜ ë°©ë²•ì„ ì‚¬ìš©)ë¥¼ ì‚¬ìš© í•œ ê²ƒë„ ì¢‹ì€ í¼í¬ë¨¼ìŠ¤ë¥¼ ë‚´ëŠ”ë° ë„ì›€ì´ ë˜ì—ˆì„ ê²ƒ ì…ë‹ˆë‹¤. ì •ë§ U-Netë³´ë‹¤ ê²°ê³¼ê°€ ì¢‹ë„¤ìš”!!! ëª¨ë¸ ì•„í‚¤í…ì²˜ Encoding Path -&amp;gt; 640X640ë¶€í„° 40X40 ê¹Œì§€ the features of interestë¥¼ ê²€ì¶œ Decoding Path -&amp;gt; 40X40ë¶€í„° 640X640ê¹Œì§€ synthesisë¥¼ ì˜ˆì¸¡ ë…¹ìƒ‰ ë¸”ë¡ -&amp;gt; regular convolutional layer, ReLu í™œì„±í•¨ìˆ˜, batch normalizationìœ¼ë¡œ êµ¬ì„± ë³´ë¼ìƒ‰ ë¸”ë¡ -&amp;gt; 3ê°œì˜ convolutional blockìœ¼ë¡œ êµ¬ì„±ë˜ëŠ”ë° ë§ˆì§€ë§‰ ë¸”ë¡3ì—ëŠ” ë¸”ë¡1ì´ ë¸”ë¡2ì™€ skipí•´ì„œ ë”í•´ì§„ residual layerê°€ ì—°ê²° ë¨ íŒŒë€ìƒ‰ ë¸”ë¡ -&amp;gt; maxpooling layerë¡œì¨ encoding pathì—ì„œ feature ì••ì¶•ì„ ìœ„í•œ downsamplingì„ í•˜ê¸° ìœ„í•´ ì‚¬ìš© ë¹¨ê°„ìƒ‰ ë¸”ë¡ -&amp;gt; deconvolutional layerë¡œ decoding pathì—ì„œ interpolationì„ ì‚¬ìš©í•œ upsamplingì„ í•˜ê¸° ìœ„í•´ ì‚¬ìš© ì°¸ê³ ìë£Œ FusionNet : A deep fully residual convolutional neural network for image segmentation in connectomics ì´ìƒìœ¼ë¡œ FusionNetì— ëŒ€í•œ ê¸€ì„ ë§ˆì¹©ë‹ˆë‹¤. ìˆ˜ì •í•´ì•¼ í•  ë‚´ìš©ì´ ìˆë‹¤ë©´ ê¼­ ë§ì”€ ë¶€íƒë“œë¦½ë‹ˆë‹¤. ë¶€ì¡±í•œ ê¸€ì´ì§€ë§Œ ëê¹Œì§€ ì½ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤!!!</summary></entry><entry><title type="html">U-Net</title><link href="http://localhost:4000/U_Net" rel="alternate" type="text/html" title="U-Net" /><published>2018-04-02T09:00:00+09:00</published><updated>2018-04-02T09:00:00+09:00</updated><id>http://localhost:4000/U_Net</id><content type="html" xml:base="http://localhost:4000/U_Net">&lt;p&gt;ë…¼ë¬¸ ë§í¬ : &lt;a href=&quot;https://arxiv.org/pdf/1505.04597.pdf&quot;&gt;U-Net: Convolutional Networks for Biomedical Image Segmentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ì´ë²ˆ ë¸”ë¡œê·¸ì˜ ë‚´ìš©ì€ Semantic Segmentationì˜ ê°€ì¥ ê¸°ë³¸ì ìœ¼ë¡œ ë§ì´ ì“°ì´ëŠ” ëª¨ë¸ì¸ U-Netì— ëŒ€í•œ ë‚´ìš©ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;U-Netì˜ ì´ë¦„ì€ ê·¸ ìì²´ë¡œ ëª¨ë¸ì˜ í˜•íƒœê°€ Uìë¡œ ë˜ì–´ ìˆì–´ì„œ ìƒê¸´ ì´ë¦„ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ë²ˆ ë¸”ë¡œê·¸ì˜ ë‚´ìš©ì„ ë³´ì‹œê¸° ì „ì— ì•ì „ì— ìˆëŠ” &lt;a href=&quot;https://modulabs-biomedical.github.io/FCN&quot;&gt;Fully Convolution for Semantic Segmentation&lt;/a&gt; ê³¼ 
&lt;a href=&quot;https://modulabs-biomedical.github.io/Learning_Deconvolution_Network_for_Semantic_Segmentation&quot;&gt;Learning Deconvolution Network for Semantic Segmentation&lt;/a&gt; ì„ ì½ê³  ë³´ì‹œë©´ ë” ë„ì›€ì´ ë˜ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤!&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;Abstractì—ì„œëŠ” ì „ì²´ì ì¸ U-Netì˜ í•µì‹¬ êµ¬ì¡°, data augmentation, ISBI challengeì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤ëŠ” ì´ì•¼ê¸°ë¥¼ í•˜ê³  ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;Deep NetworkëŠ” ë§ì€ ì–‘ì˜ annotatedëœ í•™ìŠµ ìƒ˜í”Œì„ ê°€ì§€ê³  ì„±ê³µì ì¸ trainingì„ í•´ì™”ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ë…¼ë¬¸ì—ì„œëŠ” data augmentationì„ ì˜ í™œìš©í•˜ì—¬ annotated sampleì„ ë³´ë‹¤ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” training ì „ëµì„ ë³´ì—¬ì¤ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” ì•„í‚¤í…ì³ëŠ” contracting pathì—ì„œëŠ” contextë¥¼ ìº¡ì³í•˜ê³ , ëŒ€ì¹­ì ì¸ êµ¬ì¡°ë¥¼ ì´ë£¨ëŠ” expanding pathì—ì„œëŠ” ì •êµí•œ localizationì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;

&lt;p&gt;ë…¼ë¬¸ì—ì„œ ì²˜ìŒì— ì†Œê°œí•˜ëŠ” ë‚´ìš©ì€ ì§€ë‚œ 2ë…„ë™ì•ˆ (U-Netì€ 2015ë…„ 5ì›”ì— ë°œí‘œë˜ì—ˆìŠµë‹ˆë‹¤.) deep convolution networkëŠ” ë§ì€ visual recognition ì‘ì—…ì—ì„œ ë§¤ìš° ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ì§€ë§Œ, training setì˜ í¬ê¸°ì™€ ê³ ë ¤í•  ë„¤íŠ¸ì›Œí¬ì˜ í¬ê¸° ë•Œë¬¸ì— ê·¸ ì„±ê³µì€ ì œí•œì ì´ì—ˆë‹¤ê³  ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;Convolutionë„¤íŠ¸ì›Œí¬ì˜ ì¼ë°˜ì ì¸ ìš©ë„ëŠ” ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶œë ¥ì´ ë‹¨ì¼ í´ë˜ìŠ¤ ë ˆì´ë¸”ì¸ ë¶„ë¥˜ ì‘ì—…ì— ìˆì§€ë§Œ, 
ë§ì€ ì‹œê° ì‘ì—…, íŠ¹íˆ biomedical processingì—ì„œ ì›í•˜ëŠ” ì¶œë ¥ì€ localizationì„ í¬í•¨í•´ì•¼ í•˜ë©°, ì¦‰ í´ë˜ìŠ¤ ë¼ë²¨ì€ ê° pixelì— í• ë‹¹ ë˜ì–´ì•¼ í•œë‹¤ê³  í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;U-Netì—ì„œ í•µì‹¬ìœ¼ë¡œ ë§í•˜ê³  ìˆëŠ” ë‚´ìš©ì€ ì„¸ê°€ì§€ë¡œ ìƒê°ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Convolution Encoderì— í•´ë‹¹í•˜ëŠ” Contracting Path + Convolution Decoderì— í•´ë‹¹í•˜ëŠ” Expanding Pathì˜ êµ¬ì¡°ë¡œ êµ¬ì„±. (í•´ë‹¹ êµ¬ì¡°ëŠ” Fully Convolution + Deconvolution êµ¬ì¡°ì˜ ì¡°í•©)&lt;/li&gt;
    &lt;li&gt;Expanding Pathì—ì„œ Upsampling í•  ë•Œ, ì¢€ ë” ì •í™•í•œ Localizationì„ í•˜ê¸° ìœ„í•´ì„œ Contracting Pathì˜ Featureë¥¼ Copy and Cropí•˜ì—¬ Concat í•˜ëŠ” êµ¬ì¡°.&lt;/li&gt;
    &lt;li&gt;Data Augmentation&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;ê¸°ì¡´ì—ëŠ”(&lt;a href=&quot;http://people.idsia.ch/~juergen/nips2012.pdf&quot;&gt;Ciresan et al. [1]&lt;/a&gt;) Sliding-windowì„ í•˜ë©´ì„œ ë¡œì»¬ ì˜ì—­(íŒ¨ì¹˜)ì„ ì…ë ¥ìœ¼ë¡œ ì œê³µí•´ì„œ ê° í”½ì…€ì˜ í´ë˜ìŠ¤ ë ˆì´ë¸”ì„ ì˜ˆì¸¡í–ˆì§€ë§Œ, ì´ ë°©ë²•ì€ 2ê°€ì§€ ë‹¨ì ìœ¼ë¡œ ì¸í•´ì„œ Fully Convolution Networkêµ¬ì¡°ë¥¼ ì œì•ˆí•˜ê³  ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë‘ê°€ì§€ ë‹¨ì ì€,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;ë„¤íŠ¸ì›Œí¬ê°€ ê° íŒ¨ì¹˜ì— ëŒ€í•´ ê°œë³„ì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ì•¼ í•˜ê³  íŒ¨ì¹˜ê°€ ê²¹ì³ ì¤‘ë³µì„±ì´ ë§ê¸° ë•Œë¬¸ì— ìƒë‹¹íˆ ëŠë¦¬ë‹¤.&lt;/li&gt;
    &lt;li&gt;localizationê³¼ contextì‚¬ì´ì—ëŠ” trade-offê°€ ìˆëŠ”ë°, ì´ëŠ” í° ì‚¬ì´ì¦ˆì˜ patchesëŠ” ë§ì€ max-poolingì„ í•´ì•¼í•´ì„œ localizationì˜ ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆê³ , ë°˜ë©´ ì‘ì€ ì‚¬ì´ì¦ˆì˜ patchesëŠ” í˜‘ì†Œí•œ contextë§Œì„ ë³¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Contracting Pathì—ì„œ Poolingë˜ê¸° ì „ì˜ Fetureë“¤ì€ Upsampling ì‹œì— Layerì™€ ê²°í•©ë˜ì–´ ê³  í•´ìƒë„ outputì„ ë§Œë“¤ì–´ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;í•˜ë‚˜ ë” ì¤‘ìš”í•œ ì ì€! 
ë§ì€ ìˆ˜ì˜ Feature Channelsë¥¼ ì‚¬ìš©í•˜ëŠ”ë°ìš”.
ì•„ë˜ ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì³ë¥¼ ë³´ì‹œë©´ DownSamplingì‹œì—ëŠ” 64 ì±„ë„ -&amp;gt; 1024ì±„ë„ê¹Œì§€ ì¦ê°€ ë˜ê³ ,
UpSamplingì‹œì—ëŠ” 1024 ì±„ë„ -&amp;gt; 64ì±„ë„ì„ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë„¤íŠ¸ì›Œí¬ëŠ” fully connected layersë¥¼ ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ê° layerì—ì„œ convolutionë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë‹¤ìŒìœ¼ë¡œ, U-Netì—ì„œëŠ” Segmentationì‹œ overlab-tile ì „ëµì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (ê·¸ë¦¼.2)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-04-02-U_Net/u-net_fig_2.png&quot; alt=&quot;u-net_fig_2&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Overlap-tile ì „ëµì€, U-Netì—ì„œ ë‹¤ë£¨ëŠ” ì „ì í˜„ë¯¸ê²½ ë°ì´í„°ì˜ íŠ¹ì„±ìƒ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆì˜ í¬ê¸°ê°€ ìƒë‹¹íˆ í¬ê¸° ë•Œë¬¸ì— Patch ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ Input ìœ¼ë¡œ ë„£ê³  ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

  &lt;p&gt;ì´ë•Œ &lt;code class=&quot;highlighter-rouge&quot;&gt;Fig.2&lt;/code&gt;ì—ì„œ ë³´ëŠ” ê²ƒê³¼ ê°™ì´ Border ë¶€ë¶„ì— ì •ë³´ê°€ ì—†ëŠ” ë¹ˆ ë¶€ë¶„ì„  0ìœ¼ë¡œ ì±„ìš°ê±°ë‚˜, ì£¼ë³€ì˜ ê°’ë“¤ë¡œ ì±„ìš°ê±°ë‚˜ ì´ëŸ° ë°©ë²•ì´ ì•„ë‹Œ Mirroring ë°©ë²•ìœ¼ë¡œ pixelì˜ ê°’ì„ ì±„ì›Œì£¼ëŠ” ë°©ë²• ì…ë‹ˆë‹¤.&lt;/p&gt;

  &lt;p&gt;ë…¸ë‘ìƒ‰ ì˜ì—­ì´ ì‹¤ì œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë  ì˜ì—­ì´ê³ , íŒŒë‘ìƒ‰ ë¶€ë¶„ì´ Patch ì…ë‹ˆë‹¤.&lt;/p&gt;

  &lt;p&gt;ê·¸ë¦¼ì„ í™•ëŒ€í•´ì„œ ìì„¸íˆ ë³´ì‹œë©´, ê±°ìš¸ì²˜ëŸ¼ ë°˜ì‚¬ë˜ì–´ borderë¶€ë¶„ì´ ì±„ì›Œì§„ ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-04-02-U_Net/u-net_fig_2_ex.png&quot; alt=&quot;u-net_fig_2_ex&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Overlap-tile ì´ë¼ëŠ” ì´ë¦„ì€, íŒŒë‘ìƒ‰ ë¶€ë¶„ì´ Patchë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ í•˜ê²Œ ë˜ëŠ”ë° (ìš©ì–´ëŠ”, Patch == Tile) ì´ ë¶€ë¶„ì´ ì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ ê²¹ì³ì„œ ëœ¯ì–´ë‚´ì„œ í•™ìŠµì‹œí‚¤ê¸° ë•Œë¬¸ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-04-02-U_Net/u-net_fig_2_overlap.png&quot; alt=&quot;u-net_fig_2_overlap&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-network-architecture&quot;&gt;2. Network Architecture&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-04-02-U_Net/u-net_fig_1.png&quot; alt=&quot;u-net_fig_1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Contracting PathëŠ”&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;ì „í˜•ì ì¸ Convolution network ì´ê³ ,&lt;/li&gt;
    &lt;li&gt;ë‘ë²ˆì˜ 3X3 convolutionì„ ë°˜ë³µ ìˆ˜í–‰í•˜ë©° (unpadded convolutionë¥¼ ì‚¬ìš©),&lt;/li&gt;
    &lt;li&gt;ReLUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤&lt;/li&gt;
    &lt;li&gt;2X2 max pooling ê³¼ stride 2ë¥¼ ì‚¬ìš©í•¨&lt;/li&gt;
    &lt;li&gt;downsamplingì‹œì—ëŠ” 2ë°°ì˜ feture channelì„ ì‚¬ìš©í•˜ê³ &lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;Expanding PathëŠ”&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;2X2 convolution (up-convolution)ì„ ì‚¬ìš©í•˜ê³ ,&lt;/li&gt;
    &lt;li&gt;feature channelì€ ë°˜ìœ¼ë¡œ ì¤„ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.&lt;/li&gt;
    &lt;li&gt;Contracting Pathì—ì„œ Max-Pooling ë˜ê¸° ì „ì˜ feature mapì„ Crop í•˜ì—¬ Up-Convolution í•  ë•Œ concatenationì„ í•©ë‹ˆë‹¤.&lt;/li&gt;
    &lt;li&gt;ë‘ë²ˆì˜ 3X3 convolution ë°˜ë³µí•˜ë©°&lt;/li&gt;
    &lt;li&gt;ReLUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;ë§ˆì§€ë§‰ Final Layerì—ì„œëŠ” 1X1 convolutionì„ ì‚¬ìš©í•˜ì—¬ 2ê°œì˜ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;U-Netì€ ì´ 23ê°œì˜ convolution layerê°€ ì‚¬ìš©ëìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;3-training&quot;&gt;3. Training&lt;/h2&gt;

&lt;p&gt;í•™ìŠµì€ Stochastic gradient descent ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ë…¼ë¬¸ì—ì„œëŠ” í•™ìŠµì‹œì— GPU memoryì˜ ì‚¬ìš©ëŸ‰ì„ ìµœëŒ€í™” ì‹œí‚¤ê¸° ìœ„í•´ì„œ batch sizeë¥¼ í¬ê²Œí•´ì„œ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒ ë³´ë‹¤ input tile ì˜ sizeë¥¼ í¬ê²Œ ì£¼ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•˜ëŠ”ë°ìš”, 
ì´ ë°©ë²•ìœ¼ë¡œ Batch Sizeê°€ ì‘ê¸° ë•Œë¬¸ì—, ì´ë¥¼ ë³´ì™„í•˜ê³ ì momentumì˜ ê°’ì„ 0.99ê°’ì„ ì¤˜ì„œ ê³¼ê±°ì˜ ê°’ë“¤ì„ ë” ë§ì´ ë°˜ì˜í•˜ê²Œ í•˜ì—¬ í•™ìŠµì´ ë” ì˜ ë˜ë„ë¡ í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-04-02-U_Net/u-net_fig_3.png&quot; alt=&quot;u-net_fig_3&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;softmax&quot;&gt;softmax&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-04-02-U_Net/u-net_softmax.png&quot; alt=&quot;softmax&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;cross-entropy-loss-with-wx&quot;&gt;Cross Entropy Loss with w(x)&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;ê°ê° ì •ë‹µ í”½ì…€ì—ëŒ€í•œ cross entropy lossì—ëŠ” &lt;script type=&quot;math/tex&quot;&gt;w(\mathbf x)&lt;/script&gt;ë¼ëŠ” ê°€ì¤‘ì¹˜ ê°’ì´ ì¶”ê°€ë©ë‹ˆë‹¤. 
ì—¬ê¸°ì„œ  &lt;script type=&quot;math/tex&quot;&gt;p_{l(x)}(x)&lt;/script&gt;ì˜ &lt;script type=&quot;math/tex&quot;&gt;l(x)&lt;/script&gt;ëŠ” ì •ë‹µ í´ë˜ìŠ¤ ì¦‰ ìœ„ &lt;strong&gt;softmax ìˆ˜ì‹&lt;/strong&gt;ì—ì„œ ì •ë‹µì˜ ë ˆì´ë¸”ì— í•´ë‹¹í•˜ëŠ”  &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; ê°’ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ ì…ë‹ˆë‹¤.&lt;/p&gt;

  &lt;p&gt;cross entropy í•¨ìˆ˜ëŠ” ì •ë‹µì˜ ì¶”ì •ê°’ì„ logì— ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì´ì— í•´ë‹¹í•˜ëŠ” ì •ë‹µì˜ í™•ë¥ ì„ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ì£ . 
ìˆ˜ì‹ (1)ì€ loss ê°’ì— ê°€ì¤‘ì¹˜ &lt;script type=&quot;math/tex&quot;&gt;w(\mathbf x)&lt;/script&gt;ë¥¼ ê³±í•œ í˜•íƒœì´ë©° ì´ì œ ìš°ë¦¬ê°€ ì‚´í´ë³¼ ê²ƒì€  &lt;script type=&quot;math/tex&quot;&gt;w(\mathbf x)&lt;/script&gt;ì…ë‹ˆë‹¤.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-04-02-U_Net/u-net_cross_entropy.png&quot; alt=&quot;1_cross_entropy&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;w(\mathbf x)&lt;/script&gt; &lt;strong&gt;êµ¬í•˜ëŠ” ë²• :&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-04-02-U_Net/u-net_wx.png&quot; alt=&quot;2_wx&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;w(\mathbf x)&lt;/script&gt;ëŠ” ë‘ê°œì˜ í…€ì˜ í•©ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. &lt;script type=&quot;math/tex&quot;&gt;w(\mathbf x)&lt;/script&gt;ëŠ” &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; ìœ„ì¹˜ì˜ í”½ì…€ì— ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.&lt;/p&gt;

  &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;w_c(\mathbf x)&lt;/script&gt;ëŠ”  &lt;script type=&quot;math/tex&quot;&gt;\mathbf x&lt;/script&gt; ì˜ ìœ„ì¹˜ì— í•´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤ì˜ ë¹ˆë„ìˆ˜ì— ë”°ë¼ ê°’ì´ ê²°ì •ë©ë‹ˆë‹¤.&lt;/p&gt;

  &lt;p&gt;ì¦‰ í•™ìŠµë°ì´í„°ì—ì„œ &lt;script type=&quot;math/tex&quot;&gt;\mathbf x&lt;/script&gt; í”½ì…€ì´ backgroundì¼ ê²½ìš°ê°€ ë§ì€ì§€ foregroundì¼ ê²½ìš°ê°€ ë§ì€ì§€ì˜ ë¹ˆë„ìˆ˜ì— ë”°ë¼ ê²°ì •ëœë‹¤ê³  ë³´ì‹œë©´ ë©ë‹ˆë‹¤.&lt;/p&gt;

  &lt;p&gt;ê·¸ ë’¤ì˜ exp í…€ì€ &lt;script type=&quot;math/tex&quot;&gt;d_1&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;d_2&lt;/script&gt;Â í•¨ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ”ë° &lt;script type=&quot;math/tex&quot;&gt;d_1&lt;/script&gt;Â ì€ &lt;script type=&quot;math/tex&quot;&gt;\mathbf x&lt;/script&gt; ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì„¸í¬ê¹Œì§€ì˜ ê±°ë¦¬ì´ê³  &lt;script type=&quot;math/tex&quot;&gt;d_2&lt;/script&gt;ëŠ” ë‘ë²ˆì§¸ë¡œ ê°€ê¹Œìš´ ì„¸í¬ê¹Œì§€ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.&lt;/p&gt;

  &lt;p&gt;ì¦‰  &lt;script type=&quot;math/tex&quot;&gt;\mathbf x&lt;/script&gt;ëŠ” ì„¸í¬ì‚¬ì´ì— ì¡´ì¬í•˜ëŠ” í”½ì…€ì´ë©° ë‘ ì„¸í¬ì‚¬ì´ì˜ ê°„ê²©ì´ ì¢ì„ ìˆ˜ë¡ weightë¥¼ í° ê°’ìœ¼ë¡œ ë‘ ì„¸í¬ ì‚¬ì´ê°€ ë„“ì„ ìˆ˜ë¡ weightë¥¼ ì‘ì€ ê°’ìœ¼ë¡œ ê°–ê²Œ ë©ë‹ˆë‹¤. ì´ëŠ” ê·¸ë¦¼ 3(d) ë¥¼ ë³´ì‹œë©´ ëª…í™•í•˜ê²Œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

  &lt;p&gt;ë„¤íŠ¸ì›Œí¬ íŒŒë¼ë¯¸í„°ì˜ ì´ˆê¸°í™”ëŠ” He ì´ˆê¸°í™” ë°©ë²•ì„ ì ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;31-data-augmentation&quot;&gt;3.1 Data Augmentation&lt;/h3&gt;

&lt;p&gt;Data Augmentationì€ 3 by 3 elastic ë³€í™˜ í–‰ë ¬ì„ í†µí•´ ìˆ˜í–‰í•©ë‹ˆë‹¤. &lt;a href=&quot;https://en.wikipedia.org/wiki/Transformation_matrix&quot;&gt;ì˜ìƒë³€í™˜ ë§¤íŠ¸ë¦­ìŠ¤&lt;/a&gt;ëŠ” í´ë¦­í•˜ì…”ì„œ ìœ„í‚¤ì˜ ë‚´ìš©ì„ ì°¸ì¡°í•˜ë©´ ìì„¸í•œ ë‚´ìš©ì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„¸í¬ë¥¼ ì„¸ê·¸ë©˜í…Œì´ì…˜ í•˜ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— elastic deformationì˜ ì ìš©ì´ ì„±ëŠ¥í–¥ìƒì— ë§¤ìš° í° ì—­í• ì„ í–ˆë‹¤ê³  í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;4-experiments&quot;&gt;4. Experiments&lt;/h2&gt;

&lt;p&gt;í•™ìŠµí•œ ì´í›„ ì„±ëŠ¥ ì§€í‘œëŠ” EM Segmentation challengeì—ì„œ wraping Error / Rand Error / Pixel Errorë¡œ 1ìœ„ë¥¼ í•œ ì§€í‘œë¥¼ ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-04-02-U_Net/u-net_table1.png&quot; alt=&quot;Table1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;IOU(Intersection over union) ë°©ë²•ìœ¼ë¡œ ì¸¡ì •í•œ ê²°ê³¼ë¡œëŠ” ì•„ë˜ì™€ ê°™ì´ 92% / 77.5%ë¡œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/posts/2018-04-02-U_Net/u-net_table2.png&quot; alt=&quot;Table2&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-conclusion&quot;&gt;5. Conclusion&lt;/h2&gt;

&lt;p&gt;ë§ˆì§€ë§‰ìœ¼ë¡œ ê²°ë¡ ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;U-Net êµ¬ì¡°ëŠ” ë§¤ìš° ë‹¤ë¥¸ biomedical segmentation applicationsì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ê³ , 
ì´ ì„±ëŠ¥ì„ ë³´ì¼ ìˆ˜ ìˆì—ˆë˜ ê²ƒì€ Elastic ë³€í™˜ì„ ì ìš©í•œ data augmentation ë•ë¶„ì´ê³ , 
ì´ê²ƒì€ annotated imageê°€ ë³„ë¡œ ì—†ëŠ” ìƒí™©ì—ì„œ ë§¤ìš° í•©ë¦¬ì ì´ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;í•™ìŠµí•˜ëŠ”ë° ê±¸ë ¸ë˜ ì‹œê°„ì€ NVidia Titan GPU(6GB)ë¥¼ ì‚¬ìš©í–ˆì„ë•Œ, 10ì‹œê°„ì´ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ U-Net êµ¬í˜„ì€ Caffe ê¸°ë°˜ìœ¼ë¡œ ì œê³µë˜ê³  ìˆìœ¼ë©°, U-Netì˜ ì•„í‚¤í…ì³ëŠ” ë‹¤ì–‘í•œ taskì—ì„œ ì‰½ê²Œ ì ìš©ë˜ì„œ ì‚¬ìš©ë  ê²ƒì„ í™•ì‹ í•œë‹¤ê³  í•˜ë©´ì„œ ë…¼ë¬¸ì€ ë§ˆë¬´ë¦¬ ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;Image Segmentation Taskì—ì„œ ê°€ì¥ ë§ì´ ì“°ì´ëŠ” U-Netì€ Uìí˜• ì•„ì¼€í…ì³ì™€ Fully Convolution &amp;amp; Deconvolution êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ì¢€ ë” ì •í™•í•œ Localizationì„ ìœ„í•´ì„œ Contracting Pathì˜ Featureë¥¼ Copy and Cropí•´ì„œ Expanding Pathì™€ Concatí•˜ì—¬ Upsamplingì„ í•œë‹¤ëŠ” ê²ƒì„ í™•ì‹¤í•˜ê²Œ ì•Œì•„ë‘ë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ìƒ ë¶€ì¡±í•˜ì§€ë§Œ, U-Net ë…¼ë¬¸ì— ëŒ€í•œ í¬ìŠ¤íŒ…ì„ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤. í‹€ë¦° ë¶€ë¶„ì´ ìˆê±°ë‚˜ ë³´ì¶© ë‚´ìš©ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì‹œë©´ ìˆ˜ì •í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤!&lt;/p&gt;

&lt;p&gt;ê°ì‚¬í•©ë‹ˆë‹¤.&lt;/p&gt;</content><author><name>ê°•ì€ìˆ™</name></author><category term="ë…¼ë¬¸ ë¦¬ë·°" /><summary type="html">ë…¼ë¬¸ ë§í¬ : U-Net: Convolutional Networks for Biomedical Image Segmentation</summary></entry><entry><title type="html">Bias vs. Variance ê°œë… ì •ë¦¬</title><link href="http://localhost:4000/Bias_vs_Variance" rel="alternate" type="text/html" title="Bias vs. Variance ê°œë… ì •ë¦¬" /><published>2018-01-25T09:00:00+09:00</published><updated>2018-01-25T09:00:00+09:00</updated><id>http://localhost:4000/Bias_vs_Variance</id><content type="html" xml:base="http://localhost:4000/Bias_vs_Variance">&lt;p&gt;ì´ ê¸€ì—ì„œ biasì™€ varianceì— ëŒ€í•´ ì‚´í´ë³´ë ¤ê³  í•©ë‹ˆë‹¤. biasì™€ varianceëŠ” ì´ë¯¸ ë§ì€ ê¸€ì´ë‚˜ ë¸”ë¡œê·¸ì—ì„œ ê°œë…ì ìœ¼ë¡œ ì˜ ì„¤ëª…ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ë‹¤ì‹œ ì •ë¦¬í•´ë³´ëŠ” ì´ìœ ëŠ” ê°œë…ì ìœ¼ë¡œ ì–´ëŠì •ë„ ì´í•´ëŠ” ë˜ëŠ”ë° ì¢€ ë” ìì„¸í•˜ê²Œ ë³´ë ¤ê³  í•˜ë©´, ë¸”ë¡œê·¸ë“¤ì˜ ì˜ˆì œë“¤ ê°„ì˜ ì—°ê²°ì´ ë§‰í˜€ì„œ í—·ê°ˆë¦¬ëŠ” ë¶€ë¶„ì´ ìˆì–´ ì´ ê¸€ì„ í†µí•´ í™•ì‹¤íˆ ì´í•´í•˜ê¸° ìœ„í•´ì„œ ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;bias-vs-varianceì˜-ì˜ë¯¸&quot;&gt;Bias vs. Varianceì˜ ì˜ë¯¸&lt;/h2&gt;

&lt;p&gt;biasì™€ varianceëŠ” ëª¨ë¸ì˜ loss ë˜ëŠ” errorë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” í•™ìŠµ ëª¨ë¸ì˜ bias, variance íŠ¹ì„±ì„ êµ¬ë¶„í•˜ëŠ” ì•„ë˜ì˜ ê·¸ë¦¼ì„ ë§ì´ ë³´ì•˜ìŠµë‹ˆë‹¤. ì°¸ê³ ë¡œ ì•„ë˜ ê·¸ë¦¼ì€ bias-variance trade offë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê·¸ë¦¼ì´ ì•„ë‹™ë‹ˆë‹¤. ì•„ë˜ ê·¸ë¦¼ìœ¼ë¡œ trade off ê´€ê³„ë¥¼ ì„¤ëª…í•˜ë ¤ê³  í•˜ë©´ ì—°ê²°ì´ ì˜ ì•ˆë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì œê°€ ì´ ê¸€ì„ í†µí•´ì„œ ì˜ ì—°ê²° ì‹œì¼œë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.)&lt;/p&gt;

&lt;p&gt;bias-variance trade offëŠ” ì  ì‹œ ë¯¸ë¤„ë‘ê³ , biasì™€ varianceì˜ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ëŠ”ë° ì§‘ì¤‘í•´ ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ì•„ë˜ ê·¸ë¦¼ì€ train data ë˜ëŠ” test dataì— ëŒ€í•œ ê²°ê³¼ë¥¼ biasì™€ variance ê´€ì ì—ì„œ í•´ì„í•˜ëŠ” ê·¸ë¦¼ì…ë‹ˆë‹¤. ë¶‰ì€ ìƒ‰ ì˜ì—­ì€ target, ì¦‰ ì°¸ ê°’ì„ ì˜ë¯¸í•˜ê³  íŒŒë€ ì ì€ ì¶”ì • ê°’ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ biasëŠ” ì°¸ ê°’ë“¤ê³¼ ì¶”ì • ê°’ë“¤ì˜ ì°¨ì´(or í‰ê· ê°„ì˜ ê±°ë¦¬)ë¥¼ ì˜ë¯¸í•˜ê³ , varianceëŠ” ì¶”ì • ê°’ë“¤ì˜ í©ì–´ì§„ ì •ë„ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.(ì´ ë¶€ë¶„ì€ ë’¤ì— Mean Square Error ìˆ˜ì‹ì„ í†µí•´ ë‹¤ì‹œ ì„¤ëª…í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.) biasì™€ varianceê°€ lossì´ë¯€ë¡œ, ìš°ë¦¬ëŠ” ì§ê´€ì ìœ¼ë¡œ  ë‘˜ ë‹¤ ì‘ì€ (a) ëª¨ë¸ì´ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (b)ëª¨ë¸ì€ ì¶”ì • ê°’ë“¤ì„ í‰ê· í•œ ê°’ì€ ì°¸ ê°’ê³¼ ë¹„ìŠ·í•œë°(biasê°€ ì‘ì€ë°), ì¶”ì • ê°’ë“¤ì˜ varianceê°€ ì»¤ì„œ lossê°€ í° ëª¨ë¸ì…ë‹ˆë‹¤.  (c)ëŠ” biasê°€ í¬ê³ , varianceê°€ ì‘ì€ ëª¨ë¸ì´ê³ , (d)ëŠ” ë‘˜ ë‹¤ í° ëª¨ë¸ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2018-01-25-Bias_vs_Variance/3.jpg&quot; alt=&quot;high_low_bias_variance&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ìœ„ ê·¸ë¦¼ì„ ì´ì œ train dataì™€ test data ê´€ì ì—ì„œ ì‚´í´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. train dataì—ì„œëŠ” (a)ì™€ ê°™ì€ ê²°ê³¼ ì´ì—ˆëŠ”ë°(train lossê°€ ì‘ì•˜ëŠ”ë°), test dataë¥¼ ë„£ì–´ë³´ë‹ˆ (b),(c),(d)ì˜ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤ê³  í•´ ë³´ê² ìŠµë‹ˆë‹¤. 3 ê°€ì§€ ëª¨ë‘ train dataì—ì„œëŠ” lossê°€ ì‘ì•˜ëŠ”ë° test dataì— ì ìš©í•´ ë³´ë‹ˆ lossê°€ ì»¤ì¡ŒìŠµë‹ˆë‹¤. ì™œ ê·¸ëŸ° ê²ƒì¼ê¹Œìš”?&lt;/p&gt;

&lt;p&gt;(b),(c),(d)ëª¨ë‘ ì—ëŸ¬ê°€ í¬ì§€ë§Œ ì„œë¡œ ë‹¤ë¥¸ ìœ í˜•ì˜ ì—ëŸ¬ë¥¼ ë‚˜íƒ€ë‚´ê³  ìˆìŠµë‹ˆë‹¤. ì¦‰, ì›ì¸ì´ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. varianceê°€ í° (b)ëª¨ë¸ì€ train dataì— over-fittingëœ ê²ƒì´ ì›ì¸ì´ê³ , ì´ëŠ” ë„ˆë¬´ train dataì— fittingëœ ëª¨ë¸ì„ ë§Œë“¤ì–´ì„œ test dataì—ì„œ ì˜¤ì°¨ê°€ ë°œìƒí•œ ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. biasê°€ í° (c) ëª¨ë¸ì€ &lt;u&gt;test data&lt;/u&gt;ë¥¼ ìœ„í•œ í•™ìŠµì´ ëœ ëœ ê²ƒì´ ì›ì¸ì´ê³ , ì´ëŠ” train dataì™€ test dataê°„ì˜ ì°¨ì´ê°€ ë„ˆë¬´ ì»¤ì„œ train dataë¡œë§Œ í•™ìŠµí•œ ëª¨ë¸ì€ test dataë¥¼ ë§ì¶œìˆ˜ê°€ ì—†ëŠ” ê²ƒì…ë‹ˆë‹¤. ë§Œì¼, (c) ê·¸ë¦¼ì´ train dataì— ëŒ€í•œ ê²ƒì´ë¼ë©´ train dataì— ëŒ€í•´ under-fitting ì¦‰, í•™ìŠµì´ ëœ ëœ ëª¨ë¸ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (d)ëŠ” ë‘˜ ë‹¤ì˜ ê²½ìš°ë¡œ ìƒê°í•  ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;ë°ì´í„° ê´€ì ì—ì„œ ë³´ë©´ (b)ì˜ ê²½ìš° train dataì™€ test dataì˜ ì°¨ì´ëŠ” varianceì˜ ì°¨ì´ë¼ê³  í•  ìˆ˜ ìˆê³ ,  (c)ì˜ ê²½ìš° train dataì™€ test dataì˜ ì°¨ì´ëŠ” í‰ê· ì˜ ì°¨ì´ë¼ê³ ë„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤&lt;/em&gt;. í•™ìŠµ ëª¨ë¸ì€ ì…ë ¥ Xë¥¼ Yë¡œ ì¶”ì •í•˜ëŠ” ê²ƒì¸ë°, ì…ë ¥ Xì˜ ë¶„í¬ê°€ ë°”ë€Œì–´ ë²„ë¦¬ë©´ ë°”ë€ë§Œí¼ì˜ errorê°€ ë‚  ìˆ˜ ë°–ì— ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ê·¸ë ‡ê²Œ ì„¤ê³„ë˜ì—ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. train dataì™€ test dataì˜ ì°¨ì´ê°€ ë§ì´ ë‚˜ë©´ ì–´ë–»ê²Œ í•´ì•¼í• ê¹Œìš”? ì¦‰, test dataì— ëŒ€í•´ (c)ì˜ ê²½ìš° ì–´ë–»ê²Œí•´ì•¼ í• ê¹Œìš”? í˜ë“¤ê²Œ ì„¤ê³„í•œ ëª¨ë¸ì€ ëª»ì“°ê²Œ ë˜ëŠ” ê²ƒì¼ê¹Œìš”? ìš°ì„ ì ìœ¼ë¡œëŠ” test dataì˜ ì¼ë¶€ë¥¼ train setì— í¬í•¨ ì‹œí‚¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ë°©ë²•ì€ test dataì— ëŒ€í•´ì„œë„ ì°¸ ê°’ì„ labeling í•´ì•¼í•˜ë¯€ë¡œ ë¹„ìš©ë„ ë§ì´ ë“¤ê³ , ì‹¤ í™˜ê²½ì—ì„œëŠ” labelì´ ì—†ëŠ” í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ë“¤ì–´ ì˜¬ ê²ƒì´ê¸° ë•Œë¬¸ì— ê³ ë ¤í•  ìˆ˜ ì—†ê²Œ ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë¶„ì•¼ê°€ ë°”ë¡œ Domain Adaptation(DA)) ì…ë‹ˆë‹¤. DAëŠ” test dataì˜ label(ì°¸ê°’)ì—†ì´ data setê°„ì˜ ì°¨ì´ë¥¼ ì¤„ì—¬ì£¼ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ ê¸°ì¡´ ëª¨ë¸ì˜ ì•ë‹¨ì— ì¶”ê°€í•˜ì—¬ ì…ë ¥ ë°ì´í„°ì˜ ì°¨ì´ë¥¼ ì—†ì•  ì£¼ëŠ” trickì´ë¼ê³  í•  ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤. ìš°ë¦¬ê°€ ì˜ í•™ìŠµí•œ ê¸°ì¡´ ëª¨ë¸ì— í•­ìƒ ìœ ì‚¬í•œ ì…ë ¥ì„ ë„£ì–´ ì˜¤ì°¨ë¥¼ ì¤„ì—¬ì£¼ê² ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.(DAëŠ” ë³¸ ë‚´ìš©ê³¼ ê±°ë¦¬ê°€ ìˆìœ¼ë¯€ë¡œ ê°œë…ì ìœ¼ë¡œë§Œ ì´í•´í•˜ë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.)&lt;/p&gt;

&lt;h2 id=&quot;bias-variance-trade-off&quot;&gt;Bias-Variance Trade Off&lt;/h2&gt;

&lt;p&gt;ìœ„ì˜ train-test setì˜ ê´€ê³„ê°€ bias-variance trade offë¡œ ë‚´ìš©ìœ¼ë¡œ ì—°ê²°ë©ë‹ˆë‹¤. train dataì— ë„ˆë¬´ ì˜ ë§ê²Œ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì€ ëª¨ë¸ ë³µì¡ë„ë¥¼ ë†’ì´ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. regressionì„ ì˜ˆë¡œ ìƒê°í•´ ë³´ë©´ ëª¨ë“  ë°ì´í„°ë¥¼ ì—°ê²°í•˜ëŠ” ì„ ì„ í•™ìŠµì‹œì¼°ë‹¤ë©´ ëª¨ë¸ ë³µì¡ë„ëŠ” ë§¤ìš° ë†’ê²Œ ë˜ê³  train lossëŠ” â€˜0â€™ì´ ë  ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, train dataì— ì˜ ë§ê²Œ ë§Œë“¤ê¸° ìœ„í•´ ëª¨ë¸ ë³µì¡ë„ë¥¼ ë„ˆë¬´ ë†’ì´ë©´ test dataì—ëŠ” ê·¸ë¦¼1ì˜ (b)ì²˜ëŸ¼ varianceê°€ ì»¤ì ¸ì„œ(biasëŠ” ì‘ì€ë°) total lossëŠ” ì˜¤íˆë ¤ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, ëª¨ë¸ ë³µì¡ë„ë¥¼ ë‹¨ìˆœí•˜ê²Œ ê°€ì ¸ê°€ë©´ í•™ìŠµì´ ëœë˜ì„œ ê·¸ë¦¼ 1ì˜ (c)ì²˜ëŸ¼ biasê°€ ì»¤ì„œ(varianceëŠ” ì‘ì€ë°) total lossëŠ” ì—­ì‹œ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ ë§í•˜ëŠ” biasì™€ varianceëŠ” ì„œë¡œ ìƒë°˜ë˜ì–´ì„œ ì´ë¥¼ &lt;strong&gt;bias-variance trade off&lt;/strong&gt; ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì™œ ê·¸ëŸ° ê²ƒì¼ê¹Œìš”? ì™œ ëª¨ë¸ ë³µì¡ë„ë¥¼ ë†’ì´ë©´ over-fit ë ê¹Œìš”?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2018-01-25-Bias_vs_Variance/2.jpg&quot; alt=&quot;sampling_fluctuation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ìš°ë¦¬ê°€ sub setì„ ë§Œë“¤ ë•Œ, ì „ì²´(í†µê³„ì—ì„œ ë§í•˜ëŠ” ëª¨ì§‘ë‹¨)ì—ì„œ ìƒ˜í”Œì„ ë½‘ì•„ì„œ ë§Œë“¤í…ë°, ë½‘ëŠ” ë°©ë²•, íšŸìˆ˜ ë“±ì— ë”°ë¼ ìœ„ ê·¸ë¦¼ì²˜ëŸ¼ sub set ê°„ì˜ ë³€ë™ì´ ë°œìƒí•˜ê²Œ ë©ë‹ˆë‹¤. ë‹¤ì‹œ ë§í•´ì„œ train dataì™€ test dataëŠ” ì´ ë³€ë™ ë¶„ ë§Œí¼ ë‹¤ë¥¼ ìˆ˜ ìˆëŠ” ê²ƒì…ë‹ˆë‹¤. train dataëŠ” ì´ëŸ¬í•œ ë³€ë™ì„ í¬í•¨í•˜ê³  ìˆëŠ”ë°, train errorë¥¼ ì¤„ì´ê¸° ìœ„í•´ ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ê³„ì† ë†’ì´ë©´ ì´ ë³€ë™ ë¶„ê¹Œì§€ í•™ìŠµí•˜ê²Œ ë©ë‹ˆë‹¤. ì•„ë˜ ê·¸ë¦¼ì˜ ì²« ë²ˆì§¸ê°€ ì´ëŸ¬í•œ ë‚´ìš©ì„ ì„¤ëª…í•œ ê²ƒì…ë‹ˆë‹¤. Linear-&amp;gt;Quadratic-&amp;gt;Splineìœ¼ë¡œ ê°ˆ ìˆ˜ë¡ ëª¨ë¸ ë³µì¡ë„ê°€ ì˜¬ë¼ê°€ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ê³ , Quadraticì´ detailí•œ ë¶€ë¶„ê¹Œì§€ ì¶”ì •í•˜ëŠ” ê²ƒì´ ìœ„ì—ì„œì˜ ì–¸ê¸‰ëœ ìƒ˜í”Œë§ ì‹œì˜ ë³€ë™ ë¶„ê¹Œì§€ í•™ìŠµí•œ ê²ƒì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ë˜ì˜ ë‘ë²ˆ ì§¸ ê·¸ë¦¼ì²˜ëŸ¼ ëª¨ë¸ ë³µì¡ë„ë¥¼ ê³„ì† ë†’ì´ë©´ train lossëŠ” ê³„ì†í•´ì„œ ê°ì†Œí•˜ì§€ë§Œ, sub setê°„ì˜ ë³€ë™ ë¶„ê¹Œì§€ í•™ìŠµí•˜ëŠ” ì‹œì ë¶€í„°ëŠ” test errorê°€ ì¦ê°€í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ëŠ” train dataì˜ ë³€ë™ ë¶„ê¹Œì§€ í•™ìŠµí•˜ì—¬ test dataì— ëŒ€í•œ ì¶”ì • ê°’ì˜ varianceê°€ ì¦ê°€í•œ ê·¸ë¦¼1ì˜ (b)ì™€ ê°™ì€ ìƒí™©ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ë§ˆì§€ë§‰ ê·¸ë¦¼ì²˜ëŸ¼ ëª¨ë¸ ë³µì¡ë„ê°€ ì˜¬ë¼ê°ˆ ìˆ˜ë¡ biasëŠ” ê°ì†Œí•˜ë‚˜ varianceëŠ” ì¦ê°€í•˜ëŠ” bias-variance trade off ê´€ê³„ê°€ ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë§ˆì§€ë§‰ ê·¸ë¦¼ì—ì„œ MSEëŠ” test dataì˜ total lossë¡œ ì´í•´í•˜ì‹œë©´ ë©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì°¸ê³ : &lt;a href=&quot;https://gerardnico.com/wiki/data_mining/bias_trade-off&quot;&gt;https://gerardnico.com/wiki/data_mining/bias_trade-off&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2018-01-25-Bias_vs_Variance/4.jpg&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ì„œ ìµœì ì˜ ëª¨ë¸ ë³µì¡ë„ëŠ” ìœ„ ê·¸ë¦¼ì˜ ì„¸ë²ˆ ì§¸ì²˜ëŸ¼ biasì™€ varianceê°€ êµì°¨í•˜ëŠ” ë¶€ë¶„ì—ì„œ MSE or total test loss(biasì™€ varianceì˜ í•©)ê°€ ê°€ì¥ ì‘ì€ ì ì˜ ë³µì¡ë„ë¥¼ ê°–ëŠ” ê²ƒì…ë‹ˆë‹¤. ì¦‰, ëª¨ë¸ì˜ í•™ìŠµì´ train errorì˜ ìµœì†Œê°€ ì•„ë‹Œ test errorê°€ ìµœì†Œê°€ ë˜ë„ë¡ í•´ì•¼ í•œë‹¤ëŠ” ê²ƒìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ ê³ ë ¤í•´ë³¼ ë°©ë²•ì€ ì²˜ìŒë¶€í„° train setì´ ê°–ëŠ” ë³€ë™ì„ ì‘ê²Œ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ ë°©ë²•ì´ ë°”ë¡œ n-fold cross validationìœ¼ë¡œ ì—¬ëŸ¬ data setì„ ë§Œë“¤ì–´ í‰ê· ì ìœ¼ë¡œ ì ìš©ì‹œí‚´ìœ¼ë¡œì¨ sub setê°„ì˜ ë³€ë™ì„ ì¤„ì´ëŠ” ë°©ë²•ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ìœ„ ê·¸ë¦¼ì—ì„œ total lossë¥¼ MSEë¡œ í‘œê¸°í–ˆìŠµë‹ˆë‹¤. total lossëŠ” biasì™€ variance lossë¥¼ ëª¨ë‘ í¬í•¨í•˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ê·¸ë ¸ëŠ”ë° ì§„ì§œ ê·¸ëŸ´ê¹Œìš”?&lt;/p&gt;

&lt;p&gt;ìš°ë¦¬ê°€ í”íˆ ì‚¬ìš©í•˜ëŠ” MSEë¥¼ ì •ë¦¬í•˜ì—¬ ë‹¤ì‹œ êµ¬ì„±í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ varianceì™€ biasì˜ ì œê³± í…€ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ìˆë‹¤.(sub-setì˜ ë³€ë™ ë¶„ì€ ì œì™¸í•œ ìˆ˜ì‹ì…ë‹ˆë‹¤.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2018-01-25-Bias_vs_Variance/1.jpg&quot; alt=&quot;MSE&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ìˆ˜ì‹ìœ¼ë¡œ ë¶€í„° MSEì˜ varianceì™€ biasì˜ ì˜ë¯¸ë¥¼ ë‹¤ì‹œ ì‚´í´ë³´ë©´,&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;variance&lt;/strong&gt;ëŠ” &lt;u&gt;ì¶”ì • ê°’ì˜ í‰ê· &lt;/u&gt;ê³¼ &lt;u&gt;ì¶”ì • ê°’ë“¤&lt;/u&gt;ê°„ì˜ ì°¨ì´ì— ëŒ€í•œ ê²ƒì´ê³ , &lt;strong&gt;bias&lt;/strong&gt;ëŠ” &lt;u&gt;ì¶”ì •ê°’ì˜ í‰ê· &lt;/u&gt;ê³¼ &lt;u&gt;ì°¸ ê°’ë“¤&lt;/u&gt;ê°„ì˜ ì°¨ì´ì— ëŒ€í•œ ê²ƒì…ë‹ˆë‹¤.  ê²°êµ­, varianceëŠ” ì¶”ì • ê°’ë“¤ì˜ í©ì–´ì§„ ì •ë„ì´ê³ , biasëŠ” ì°¸ ê°’ê³¼ ì¶”ì • ê°’ì˜ ê±°ë¦¬ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ ìˆ˜ì‹ì„ ë³´ë©´ &lt;strong&gt;&lt;u&gt;varianceëŠ” lossë¥¼ ì˜ë¯¸í•˜ì§€ë§Œ, ì°¸ ê°’ê³¼ëŠ” ê´€ê³„ì—†ì´ ì¶”ì • ê°’ë“¤ì˜ í©ì–´ì§„ ì •ë„ë§Œì„ ì˜ë¯¸&lt;/u&gt;&lt;/strong&gt;í•˜ê³  ìˆìŒì„ ìœ ë…í•´ì•¼ í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;MSEê°€ biasì™€ varianceë¡œ êµ¬ì„±ë˜ì–´ ìˆê³  bias-variance ì‚¬ì´ì— trade off ê´€ê³„ì¸ë°, ìš°ë¦¬ê°€ í•™ìŠµí•˜ë©´ ì™œ MSEëŠ” ì‘ì•„ì§€ê³  â€˜0â€™ì— ê°€ê¹Œì´ ê°ˆê¹Œìš”? ì—¬ê¸°ì„œëŠ” trade off ê´€ê³„ê°€ ì—†ëŠ” ê±¸ê¹Œìš”?&lt;/p&gt;

&lt;p&gt;ìœ„ì˜ MSEì˜ ìˆ˜ì‹ì„ ë³´ë©´ biasì™€ varianceê°€ ëª¨ë‘ ì œê³± í…€ì´ë¯€ë¡œ ë‘˜ ë‹¤ ì–‘ìˆ˜ ì…ë‹ˆë‹¤. ì¦‰ MSEê°€ ê³ ì •ë˜ë©´ í•˜ë‚˜ê°€ ì»¤ì§€ë©´ í•˜ë‚˜ëŠ” ì‘ì•„ì§€ëŠ” trade off ê´€ê³„ì— ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ì™œ í•™ìŠµì„ í•˜ë©´ â€˜0â€™ì— ê°€ê¹Œì´ ìˆ˜ë ´í• ê¹Œìš”?&lt;/p&gt;

&lt;p&gt;ìš°ë¦¬ëŠ” í•™ìŠµí•  ë•Œ biasë‚˜ varianceì˜ ì–´ëŠ í•œìª½ì„ ë³´ê³  í•™ìŠµí•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì´ ë‘˜ì„ ë”í•œ MSEê°€ ì‘ì•„ì§€ë„ë¡ í•™ìŠµì„ í•˜ê¸° ë•Œë¬¸ì— ìµœì  ê°’ì„ ì•Œì•„ì„œ ì°¾ì•„ í•™ìŠµì„ í•˜ê²Œ ë©ë‹ˆë‹¤.(ì•„ë§ˆë„ ë‘ ê°’ì´ ê±°ì˜ ê°™ì„ ë•Œ ìµœì  ê°’ì´ ë  ê²ƒì…ë‹ˆë‹¤.) ìš°ë¦¬ê°€ ì£¼ë¡œ ê³ ë¯¼í•´ì•¼í•˜ëŠ” ê²ƒì€ train dataë“¤ì˜ b-v trade offê°€ ì´ë‹ˆë¼ train í›„ test í•  ë•Œì˜ b-v trade offë¼ê³  ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ì•ì„œ ì–¸ê¸‰í•œ ìƒ˜í”Œë§ ì‹œ ë°œìƒí•˜ëŠ” sub setì˜ ë³€ë™ ë“¤ì— ëŒ€í•´ ê³ ë ¤í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.  train ì—ì„œ MSEì˜ ìµœì  ì ì„ ì°¾ì•˜ëŠ”ë° train setê³¼ test setì˜ ì°¨ì´ë¡œ test setì—ì„œëŠ” ì´ê²ƒì´ ìµœì ì ì´ ì•„ë‹ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. (ë‹¨, train errorê°€ ì»¤ì„œ train errorì— ëŒ€í•œ ë¶„ì„ì„ í•  ë•ŒëŠ” trainì˜ b-vì— ëŒ€í•´ì„œ ê³ ë¯¼ì´ í•„ìš”í•  ê²ƒ ê°™ë„¤ìš”.)&lt;/p&gt;

&lt;p&gt;b-v trade offë¥¼ í•œë²ˆ ë” ë°˜ë³µí•´ ë³´ë©´, ëª¨ë¸ ë³µì¡ë„ë¥¼ ë†’ì´ë©´ train dataì— ëŒ€í•œ biasì™€ varianceëŠ” ê³„ì†í•´ì„œ ëª¨ë‘ ê°ì†Œí•©ë‹ˆë‹¤(bias+varianceì´ ì‘ì•„ì§€ë„ë¡ í•™ìŠµì‹œí‚¤ë¯€ë¡œ). ê·¸ëŸ°ë° test dataë¡œ í‰ê°€ë¥¼ í•´ë³´ë©´ MSE lossê°€ ì–´ëŠì‹œì ë¶€í„° ì»¤ì§€ëŠ”ë°, ì»¤ì§€ëŠ” ì´ìœ ëŠ” test dataì˜ MSE loss ì¤‘ì—ì„œ varianceê°€ ë‹¤ì‹œ ì»¤ì§€ê¸° ë•Œë¬¸ì´ë¼ê³  ì´í•´í•˜ë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ê·¸ëŸ¼ ë”¥ëŸ¬ë‹ì€ ì—„ì²­ë‚˜ê²Œ ë³µì¡ë„ ë†’ì€ ëª¨ë¸ì„ ë§Œë“œëŠ”ë° ì™œ test dataë„ ì˜ ë§ì¶œ ìˆ˜ ìˆë‹¤ê³  í• ê¹Œìš”? over-fitting ë¬¸ì œê°€ ì—†ì„ê¹Œìš”?&lt;/p&gt;

&lt;p&gt;ë”¥ëŸ¬ë‹ë„ ë˜‘ê°™ì´ b-v trade offë¥¼ í”¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì€ ê·¸ë˜ì„œ big ë°ì´í„°ê°€ ì „ì œê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. big ë°ì´í„°ë¼ëŠ” ê²ƒì€ train dataê°€ ë§ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ê³ , ì´ëŠ” ê±°ì˜ ì „ì²´ ë°ì´í„°(ë˜ëŠ” ëª¨ì§‘ë‹¨)ì™€ ë¹„ìŠ·í•˜ë‹¤ê³  í• ìˆ˜ ìˆìœ¼ë©°, ì•ì„œ ë§í•œ sampling ë³€ë™ì´ ê±°ì˜ ì—†ë‹¤ëŠ” ê²ƒì„ ì „ì œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ëª¨ë¸ ë³µì¡ë„ë¥¼ ë„ ë†’ì¼ ìˆ˜ ìˆëŠ” ê²ƒì…ë‹ˆë‹¤. ë§Œì¼ train dataê°€ ì ì€ ìƒíƒœë¡œ ë³µì¡í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì ìš©í•˜ë©´ over-fitting ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì „ì œê°€ ê·¸ë ‡ë‹¤ëŠ” ê²ƒì´ê³  ëª¨ë“  ê²½ìš°ì— big ë°ì´í„°ê°€ ìˆëŠ” ê²ƒì€ ì•„ë‹ˆì—¬ì„œ ë”¥ëŸ¬ë‹ì—ì„œë„ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ì—†ì• ê¸° ìœ„í•œ ë‹¤ì–‘í•œ trick(regularization, dropout, domain adaptation ë“±)ì´ ì¡´ì¬í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ê²°êµ­, ë”¥ëŸ¬ë‹ì—ì„œì˜ ë‹¤ì–‘í•œ trickë“¤ì€ lossë¥¼ ì¤„ì´ê¸° ìœ„í•œ ê²ƒì´ê³  , ì´ lossëŠ” biasì™€ varianceë¡œ ì´ë£¨ì–´ì¡Œë‹¤ëŠ” ê²ƒì„ ê¸°ì–µí•˜ë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ëŸ°í•œ trickë“¤ì˜ íš¨ê³¼ë¥¼ bias-variance ê´€ì ì—ì„œ ìƒê°í•´ë³´ë©´ ë‹¤ì–‘í•œ ë”¥ëŸ¬ë‹ trickë“¤ì— ëŒ€í•œ ë” ì¢‹ì€ ì´í•´ê°€ ë˜ì§€ ì•Šì„ê¹Œ ìƒê°í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´í•´ ì•ˆë˜ëŠ” ë¶€ë¶„ì´ë‚˜ í‹€ë¦° ë‚´ìš©ìˆìœ¼ë©´ comment ë¶€íƒë“œë¦½ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ë‹¤ìŒì— ì‹œê°„ì´ ë˜ë©´ ensemble ê¸°ë²•ì¸ baggingê³¼ boostingì„ ì‚¬ìš©í–ˆì„ ë•Œ bias, varianceê°€ ì–´ë–»ê²Œ ë‹¬ë¼ì§€ëŠ”ì§€ í•´ì„í•´ë³¼ ì˜ˆì •ì…ë‹ˆë‹¤.&lt;/p&gt;</content><author><name>í™ê·œì„</name></author><category term="ê°œë… ì •ë¦¬" /><summary type="html">ì´ ê¸€ì—ì„œ biasì™€ varianceì— ëŒ€í•´ ì‚´í´ë³´ë ¤ê³  í•©ë‹ˆë‹¤. biasì™€ varianceëŠ” ì´ë¯¸ ë§ì€ ê¸€ì´ë‚˜ ë¸”ë¡œê·¸ì—ì„œ ê°œë…ì ìœ¼ë¡œ ì˜ ì„¤ëª…ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ë‹¤ì‹œ ì •ë¦¬í•´ë³´ëŠ” ì´ìœ ëŠ” ê°œë…ì ìœ¼ë¡œ ì–´ëŠì •ë„ ì´í•´ëŠ” ë˜ëŠ”ë° ì¢€ ë” ìì„¸í•˜ê²Œ ë³´ë ¤ê³  í•˜ë©´, ë¸”ë¡œê·¸ë“¤ì˜ ì˜ˆì œë“¤ ê°„ì˜ ì—°ê²°ì´ ë§‰í˜€ì„œ í—·ê°ˆë¦¬ëŠ” ë¶€ë¶„ì´ ìˆì–´ ì´ ê¸€ì„ í†µí•´ í™•ì‹¤íˆ ì´í•´í•˜ê¸° ìœ„í•´ì„œ ì…ë‹ˆë‹¤.</summary></entry><entry><title type="html">Learning Deconvolution Network for Semantic Segmentation</title><link href="http://localhost:4000/Learning_Deconvolution_Network_for_Semantic_Segmentation" rel="alternate" type="text/html" title="Learning Deconvolution Network for Semantic Segmentation" /><published>2018-01-03T09:00:00+09:00</published><updated>2018-01-03T09:00:00+09:00</updated><id>http://localhost:4000/Learning_Deconvolution_Network_for_Semantic_Segmentation</id><content type="html" xml:base="http://localhost:4000/Learning_Deconvolution_Network_for_Semantic_Segmentation">&lt;p&gt;&lt;a href=&quot;http://arxiv.org/abs/1505.04366&quot;&gt;Noh, H., Hong, S., and Han, B. Learning Deconvolution Network for Semantic Segmentation. ICCV, 2015.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;ì´ë²ˆ ë…¼ë¬¸ì€ &lt;a href=&quot;https://modulabs-biomedical.github.io/FCN&quot;&gt;ì•ì„œ ë‹¤ë¤˜ë˜ Fully Convolutional Networks&lt;/a&gt;ì™€ ê°™ì€ ë…„ë„(2015)ì— ë‹¤ë¥¸ í•™íšŒ(FCNì€ CVPR, ë³¸ ë…¼ë¬¸ì€ ICCV)ì— ë°œí‘œëœ ë…¼ë¬¸ì…ë‹ˆë‹¤. FCNì´ë‚˜ ì´í›„ì— ë‹¤ë£° UNetë³´ë‹¤ëŠ” ë‹¤ì†Œ ì¸ê¸°ê°€ ì ì—ˆì§€ë§Œ, FCNì´ ê°€ì§„ í•œê³„ë¥¼ ì˜ ì§šì–´ì£¼ì…¨ë‹¤ëŠ” ì ì—ì„œ ê³µë¶€ì— ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;fcnì˜-ë¬¸ì œì &quot;&gt;FCNì˜ ë¬¸ì œì &lt;/h2&gt;

&lt;h3 id=&quot;í¬ê¸°ì—-ì•½í•˜ë‹¤&quot;&gt;í¬ê¸°ì— ì•½í•˜ë‹¤&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2018-01-03-Learning_Deconvolution_Network_for_Semantic_Segmentation/fig1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ìœ„ì˜ ì˜ˆì‹œë“¤ì²˜ëŸ¼ FCNì˜ ì¶”ë¡  ê²°ê³¼ë¥¼ ë³´ë©´, ëŒ€ìƒ ë¬¼ì²´ê°€ ë„ˆë¬´ í° ê²½ìš°(a)ì—ëŠ” íŒŒí¸í™”ë˜ê³ , ë„ˆë¬´ ì‘ì€ ê²½ìš°(b)ì—ëŠ” ë°°ê²½ìœ¼ë¡œ ë¬´ì‹œë˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. FCNì—ì„œëŠ” receptive field(ìƒìœ„ ë ˆì´ì–´ì˜ í•œ ì§€ì ì—ì„œ ì°¸ì¡°í•˜ëŠ” í•˜ìœ„ ë ˆì´ì–´ì˜ ì˜ì—­)ì˜ í¬ê¸°ê°€ ê³ ì •ë˜ì–´, ë‹¨ì¼ ë°°ìœ¨(scale)ë§Œì„ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì´ ë¬¸ì œì˜ ì›ì¸ì´ë¼ê³  ë³¸ ë…¼ë¬¸ì€ ì§€ì í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ë ˆì´ì–´ì˜ ê²°ê³¼ë¥¼ ì¡°í•©í•˜ëŠ” skip êµ¬ì¡°ê°€ ì´ëŸ¬í•œ í˜„ìƒì„ ì™„í™”ì‹œì¼œì£¼ê¸°ëŠ” í•˜ì§€ë§Œ, ê·¼ë³¸ì ì¸ í•´ë²•ì€ ì•„ë‹ˆë¼ëŠ” ì£¼ì¥ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;ë””í…Œì¼ì—-ì•½í•˜ë‹¤&quot;&gt;ë””í…Œì¼ì— ì•½í•˜ë‹¤&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2018-01-03-Learning_Deconvolution_Network_for_Semantic_Segmentation/fig5.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;FCNì´ ë¹„ë¡ ê¸°ì¡´ ê¸°ë²•ë“¤ì— ë¹„í•´ í° ë°œì „ì„ ì´ë£¨ì—ˆì§€ë§Œ, ì„¸ë¶€ì ì¸ ì˜ì—­ì„ ì°¾ì•„ë‚´ëŠ” ë°ì—ì„œëŠ” ì•„ì§ ê°œì„ ì˜ ì—¬ì§€ê°€ ìˆë‹¤ê³  ì´ ë…¼ë¬¸ì€ ë³´ê³  ìˆìŠµë‹ˆë‹¤. FCNì—ì„œëŠ” deconvolutionì— ë“¤ì–´ê°€ëŠ” ì…ë ¥ë¶€í„° ì´ë¯¸ ì„¸ë¶€ ë¬˜ì‚¬ê°€ ë–¨ì–´ì§€ê³ , deconvolution ê³¼ì • ìì²´ë„ ì¶©ë¶„íˆ ê¹Šì§€ ì•Šê³  ë„ˆë¬´ ë‹¨ìˆœí•˜ë‹¤ê³  ë§í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;ë…¼ë¬¸ì˜-í•´ë²•&quot;&gt;ë…¼ë¬¸ì˜ í•´ë²•&lt;/h2&gt;

&lt;h3 id=&quot;ë„¤íŠ¸ì›Œí¬-êµ¬ì¡°&quot;&gt;ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2018-01-03-Learning_Deconvolution_Network_for_Semantic_Segmentation/fig2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ë¶€ì¡±í•˜ë©´ ë” ë„£ìœ¼ë©´ ë©ë‹ˆë‹¤. FCNì—ì„œëŠ” CNNì˜ ê²°ê³¼ë¥¼ ì…ë ¥ ì´ë¯¸ì§€ì˜ ì›ë˜ ì°¨ì›ìœ¼ë¡œ í™•ëŒ€(upsampling)í•˜ëŠ” ë°ì— deconvolutionì„ ì‚¬ìš©í–ˆì§€ë§Œ, ì´ ë…¼ë¬¸ì—ì„œëŠ” deconvolution ì‹œ ì°¨ì›ì„ ìœ ì§€í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ, CNN(ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ ê±´ VGG-16)ì˜ convolutionë§Œí¼ ë ˆì´ì–´ ìˆ«ìë¥¼ ëŠ˜ë ¸ìŠµë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ê±°ìš¸ì— ë¹„ì¶˜ ëª¨ì–‘ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2018-01-03-Learning_Deconvolution_Network_for_Semantic_Segmentation/fig3.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CNNìœ¼ë¡œ ì¸í•´ ì›ë˜ ì´ë¯¸ì§€ë³´ë‹¤ ì¶•ì†Œëœ ì°¨ì› í¬ê¸°ëŠ” unpoolingìœ¼ë¡œ ë³µì›í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ unpoolingì´ë€ CNNì˜ max pooling ì‹œì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ê¸°ì–µí–ˆë‹¤ê°€, ì›ë˜ ìœ„ì¹˜ë¡œ ê·¸ëŒ€ë¡œ ë³µì›í•´ì£¼ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2018-01-03-Learning_Deconvolution_Network_for_Semantic_Segmentation/fig4.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê·¸ íš¨ê³¼ëŠ” ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ìŠµë‹ˆë‹¤. (b)ì—ì„œ (c)ë¡œ ê°ˆ ë•Œì˜ unpoolingì— ì˜í•´, í•´ìƒë„ê°€ ì»¤ì§€ëŠ” ëŒ€ì‹  ì‹ í˜¸ê°€ í©ì–´ì ¸ì„œ í¬ì†Œ(sparse)í•´ì§‘ë‹ˆë‹¤. ì´ê²ƒì„ (c)ì—ì„œ (d)ë¡œ deconvolutionì„ ê±°ì¹˜ë©´, ë””í…Œì¼ì„ ì‚´ë ¤ë‚´ë©´ì„œ ì‹ í˜¸ê°€ ê³ ë¥´ê²Œ ë°€ì§‘(dense)ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê³¼ì •ì´ ë°˜ë³µë˜ì ë…¸ì´ì¦ˆë„ ì ì°¨ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ë¼ì§€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h3 id=&quot;í•™ìŠµ-ë°-ì¶”ë¡ -ë°©ì‹&quot;&gt;í•™ìŠµ ë° ì¶”ë¡  ë°©ì‹&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2018-01-03-Learning_Deconvolution_Network_for_Semantic_Segmentation/edge-box.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ë‹¨ì¼ ë°ì´í„°ì…‹ì—ì„œ ë‹¤ì–‘í•œ í¬ê¸°ì˜ ì‚¬ë¡€ë“¤ì„ í•™ìŠµí•˜ê¸° ìœ„í•´, ë…¼ë¬¸ì—ì„œëŠ” &lt;a href=&quot;&quot;&gt;edge-box&lt;/a&gt;ë¼ëŠ” object proposal ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë¬´ì–¸ê°€ ìˆì„ë§Œí•œ ì˜ì—­ì„ ë‹¤ì–‘í•œ í¬ê¸°ì˜ ìƒìë¡œ ê³¨ë¼ëƒ…ë‹ˆë‹¤. í•™ìŠµ ì‹œì—ëŠ” ìš°ì„  ì‹¤ì œ ì •ë‹µì´ ê°€ìš´ë°ì— ë“¤ì–´ê°€ë„ë¡ ì˜ë¼ë‚¸(crop) ì´ë¯¸ì§€ë“¤ë¡œ 1ì°¨ í•™ìŠµì„, ê·¸ ë‹¤ìŒ edge-boxì˜ ê²°ê³¼ë¬¼ ì¤‘ ì‹¤ì œ ì •ë‹µê³¼ ì˜ ê²¹ì¹˜ëŠ” ê²ƒë“¤ì„ í™œìš©í•˜ì—¬ ì¡°ê¸ˆ ë” ì‹¬ë„ìˆëŠ” 2ì°¨ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2018-01-03-Learning_Deconvolution_Network_for_Semantic_Segmentation/fig6.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì´ë ‡ê²Œ í•™ìŠµì— ì‚¬ìš©ëœ edge-boxëŠ” ì¶”ë¡  ì‹œì—ë„ ì‚¬ìš©ë˜ëŠ”ë°, ì¶”ë¡  ì‹œ ì‚¬ìš©í•˜ëŠ” object proposalì˜ ìˆ˜(ìƒì ìˆ˜)ë¥¼ ì¦ê°€ì‹œí‚¬ ìˆ˜ë¡ ì„±ëŠ¥ì€ ì¢‹ì•„ì§„ë‹¤ê³  í•©ë‹ˆë‹¤. ë¬¼ë¡  ê·¸ë§Œí¼ ê³„ì‚°ëŸ‰ê³¼ ì‹œê°„ì€ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;ê²°ê³¼&quot;&gt;ê²°ê³¼&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2018-01-03-Learning_Deconvolution_Network_for_Semantic_Segmentation/fig7.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ì´ë ‡ê²Œ ì„¸ì‹¬í•˜ê²Œ ì„¤ê³„ë˜ê³  í•™ìŠµëœ ê²°ê³¼ëŠ” FCNì´ ì‹¤ìˆ˜í•˜ëŠ” ë¬¼ì²´ë“¤ë„ ë³´ë‹¤ ì„¸ë°€í•˜ê²Œ ì˜ ì°¾ì•„ë‚´ëŠ” ëª¨ìŠµì„ ë³´ì…ë‹ˆë‹¤. ë‹¤ë§Œ FCNì´ ì˜ ë§ì¶”ëŠ” ê³³ì—ì„œ ì‹¤ìˆ˜ë¥¼ í•  ë•Œë„ ìˆëŠ”ë°, ê²°êµ­ ë‘˜ì„ ì•™ìƒë¸”í•˜ì—¬ conditional random fieldë¡œ í›„ì²˜ë¦¬í•˜ë©´ ë‘ ê°€ì§€ ëª¨ë¸ì„ ëª¨ë‘ ë›°ì–´ë„˜ê²Œ ë˜ì–´, FCNê³¼ ìƒí˜¸ ë³´ì™„ì ì¸ ê´€ê³„ì— ìˆë‹¤ê³  ë…¼ë¬¸ì€ ë§ºìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h2 id=&quot;ì¶”ê°€-ì°¸ê³ -ë¬¸í—Œ&quot;&gt;ì¶”ê°€ ì°¸ê³  ë¬¸í—Œ&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.matthewzeiler.com/wp-content/uploads/2017/07/cvpr2010.pdf&quot;&gt;Zeiler, M. D. et al. Deconvolutional Networks. CVPR, 2010.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/edge-boxes-locating-object-proposals-from-edges/&quot;&gt;Zitnick, L. and Dollar, P. Edge Boxes: Locating Object Proposals from Edges. ECCV, 2014.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>ì˜¤ìƒì¤€</name></author><category term="ë…¼ë¬¸ ë¦¬ë·°" /><summary type="html">Noh, H., Hong, S., and Han, B. Learning Deconvolution Network for Semantic Segmentation. ICCV, 2015.</summary></entry><entry><title type="html">Fully Convolutional Networks for Semantic Segmentation</title><link href="http://localhost:4000/FCN" rel="alternate" type="text/html" title="Fully Convolutional Networks for Semantic Segmentation" /><published>2017-12-21T19:00:00+09:00</published><updated>2017-12-21T19:00:00+09:00</updated><id>http://localhost:4000/FCN</id><content type="html" xml:base="http://localhost:4000/FCN">&lt;p&gt;ë…¼ë¬¸ ë§í¬ : &lt;a href=&quot;https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf&quot;&gt;Fully Convolutional Networks for Semantic Segmentation&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Semantic SegmentationëŠ” ì˜ìƒì„ pixelë‹¨ìœ„ë¡œ ì–´ë–¤ objectì¸ì§€ classification í•˜ëŠ” ê²ƒì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì–¸ì œë‚˜ ê°•ë ¥ì¶”ì²œí•˜ëŠ”) &lt;a href=&quot;http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture11.pdf&quot;&gt;cs231n ê°•ì˜ ìë£Œ&lt;/a&gt;ë¥¼ ë³´ì‹œë©´ ì‰½ê²Œ ì˜ ë‚˜ì™€ ìˆì£ .&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2017-12-21-FCN/fig1.jpg&quot; alt=&quot;&quot; /&gt;
Figure 1. Computer Vision Tasks&lt;/p&gt;

&lt;p&gt;ì˜ˆì „ì—ëŠ” ì´ë ‡ê²Œ pixel ë‹¨ìœ„ë¡œ classificationì„ í•˜ê¸° ìœ„í•´,&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ê·¸ë¦¼ 2ì™€ ê°™ì´ ì¼ì • ì˜ì—­ì„ í¬í•¨í•˜ëŠ” windowë¥¼ ë§Œë“¤ê³ ,&lt;/li&gt;
  &lt;li&gt;window ë‚´ ì˜ìƒì˜ objectë¥¼ classifiyí•´ì„œ&lt;/li&gt;
  &lt;li&gt;window ì¤‘ì•™ì˜ pixelì˜ class ê°’ì´ë¼ê³  ê°„ì£¼í•˜ëŠ”&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ë°©ì‹ì„ ì£¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2017-12-21-FCN/fig2.jpg&quot; alt=&quot;&quot; /&gt;
Figure 2.&lt;/p&gt;
&lt;strike&gt; ê·¸ë¦¼ì´ í•„ìš”í•´ì„œ ì»¤í”¼ìˆ–ì—ì„œ ì‘ì—…ì¤‘ì— ê¸‰ì¡°ë¥¼...&lt;/strike&gt;

&lt;p&gt;ë‹¹ì—°íˆ 
&lt;strong&gt;ê³„ì‚°ëŸ‰ì˜ ë¬¸ì œ&lt;/strong&gt; ì™€ global informationì„ ì‚¬ìš©í•˜ì§€ ëª»í•˜ê³  windowë¼ëŠ” ì œí•œëœ ì˜ì—­ì˜ &lt;strong&gt;local informationë§Œ ì‚¬ìš©í•œë‹¤&lt;/strong&gt; ëŠ” ë¬¸ì œê°€ ìˆì„ ê²ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì´ ë…¼ë¬¸ì—ì„œëŠ” 
local featureì™€ global featureë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ê³ 
ê³„ì‚°ëŸ‰ ì¡ì•„ë¨¹ëŠ” ì£¼ë²”ì¸ fully connected layerë¥¼ ì—†ì•¤ CNN architectureë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;network-architecture&quot;&gt;Network Architecture&lt;/h2&gt;
&lt;p&gt;Fully Convolutional Networksì˜ êµ¬ì¡°ëŠ” ë‹¤ìŒ ê·¸ë¦¼ 3ê³¼ ê°™ìœ¼ë©°, í¬ê²Œ 4ê°€ì§€ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ì´ ëœë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2017-12-21-FCN/fig3.jpg&quot; alt=&quot;&quot; /&gt;
Figure 3. Architecture of Fully Convolutional Networks&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;(1) Feature Extraction&lt;/strong&gt; : 
 ì¼ë°˜ì ì¸ CNNì˜ êµ¬ì¡°ì—ì„œ ë§ì´ ë³´ì´ëŠ” conv layerë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 
 &lt;strong&gt;(2) Feature-level Classification&lt;/strong&gt; : 
 ì¶”ì¶œëœ Feature mapì˜ pixel í•˜ë‚˜í•˜ë‚˜ë§ˆë‹¤ classificationì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ ë•Œ classificationëœ ê²°ê³¼ëŠ” ë§¤ìš° coarseí•©ë‹ˆë‹¤. (ê·¸ë¦¼ 3ì—ì„œ ì´ˆë¡ìƒ‰ ë°•ìŠ¤ì— tabby cat classì— ëŒ€í•œ Classification ê²°ê³¼ ì°¸ê³ ) 
 &lt;strong&gt;(3) Upsampling&lt;/strong&gt; :
 coarse í•œ ê²°ê³¼ë¥¼ backward strided convolution ì„ í†µí•´ upsamplingí•˜ì—¬ ì›ë˜ì˜ image sizeë¡œ í‚¤ì›Œì¤ë‹ˆë‹¤. 
&lt;strong&gt;(4) Segmentation&lt;/strong&gt; : 
ê° classì˜ upsamplingëœ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ë‚˜ì˜ Segmentation  ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ê·¸ëŸ¬ë©´, ê° ë„¤íŠ¸ì›Œí¬ì˜ ë‚´ë¶€ë“¤ì„ í•œë²ˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;####&lt;em&gt;Feature Extraction&lt;/em&gt;
&lt;a href=&quot;https://arxiv.org/abs/1409.1556&quot;&gt;VGG-19 network&lt;/a&gt;ë¥¼ feature extractorë¡œ ì‚¬ìš©í•œë‹¤ê³  ê°€ì •ì„ í•´ë´…ì‹œë‹¤. ì´ ê²½ìš° conv1 ~ conv5 layer ( or pool5 layer) ê¹Œì§€ í†µê³¼í•˜ë©´ì„œ featureë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ë‚®ì€ layerì˜ ê²½ìš° ì‘ì€ receptive fieldë¥¼ ì§€ë‹ˆë¯€ë¡œ ì‘ì€ í¬ê¸°ì˜ featureê°€, ë†’ì€ layerì˜ ê²½ìš° ë†’ì€ receptive fieldë¥¼ ì§€ë‹ˆë¯€ë¡œ í° í¬ê¸°ì˜ featureê°€ ì¶”ì¶œë˜ê²Œ ë˜ì£ .
ì´ë ‡ê²Œ ì¶”ì¶œëœ ìµœì¢… feature map (conv5 or pool5 layer)ì„ ì´ìš©í•˜ì—¬ ë‹¤ìŒ ë‹¨ê³„ì—ì„œ coarseí•œ segmentation map ì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2017-12-21-FCN/fig4.jpg&quot; alt=&quot;&quot; /&gt;
Figure 4. Feature Extraction on VGG-19 Networks&lt;/p&gt;

&lt;h4 id=&quot;feature-level-classification&quot;&gt;&lt;em&gt;Feature-level Classification&lt;/em&gt;&lt;/h4&gt;

&lt;p&gt;ì›ë˜ VGG networkëŠ” ì´ë ‡ê²Œ ì¶”ì¶œëœ featureì˜ ë’¤ì— 4096, 4096, 1000ìœ¼ë¡œ ì´ì–´ì§€ëŠ” fully connected layerë¥¼ ì—°ê²°í•˜ì—¬ classificationì„ í•©ë‹ˆë‹¤ë§Œ(ê·¸ë¦¼ 4), ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ° fully connected layerë¥¼ ì—†ì• ë²„ë¦½ë‹ˆë‹¤. ê·¸ë¦¬ê³ , 1x1 conv layerë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. ê·¸ë¦¼ 3ì— ë³´ì‹œë©´ 4096, 4096, 21 ì´ë¼ê³  í‘œí˜„ëœ 1x1 conv layerë¥¼ ë³´ì‹¤ ìˆ˜ ìˆëŠ”ë°ìš”. 
(1000ì´ 21ë¡œ ë°”ë€ ì´ìœ ëŠ” ì´ ë…¼ë¬¸ì—ì„œëŠ” PASCAL VOC datasetìœ¼ë¡œ ì‹¤í—˜ì„ í•˜ëŠ”ë°, ê·¸ ë°ì´í„°ì˜ í´ë˜ìŠ¤ê°€ 20ê°œ + background ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.)
ì´ 1x1 conv ì˜ ê²°ê³¼ë¬¼ì´ ê²°êµ­ ê° classì˜ feature map ìƒì—ì„œì˜ classifiation (ì¦‰, segmentation) ì´ ë©ë‹ˆë‹¤. ê·¸ë¦¼ 3ì— ë³´ë©´ conv8(ë§ˆì§€ë§‰ 1x1 conv) layerì˜ depth channel ì¤‘ì—ì„œ tabby catì— í•´ë‹¹í•˜ëŠ” classì˜ feature map  ìƒì—ì„œì˜ classification (ì¦‰, segmentation) ê²°ê³¼ heatmap ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ 1x1 conv layerì—ì„œ depth channelì€ ê° classë¥¼ ì˜ë¯¸í•˜ë¯€ë¡œ, ì–´ë–¤ classì˜ segmentation heatmapë„ ì¶”ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h4 id=&quot;upsampling&quot;&gt;&lt;em&gt;Upsampling&lt;/em&gt;&lt;/h4&gt;

&lt;p&gt;ê·¸ëŸ°ë° feature map levelì—ì„œ segmentation í•œ ê²°ê³¼ëŠ” ë„ˆë¬´ coarseí•œ ê²°ê³¼ì…ë‹ˆë‹¤. (ê·¸ë¦¼ 3ì˜ tabby cat heatmap ë³´ë©´ ê¹ë‘ê¸°ì²˜ëŸ¼â€¦) ë”°ë¼ì„œ, ì´ coarseí•œ heatmapì„ denseí•˜ê²Œ (ì›ë˜ì˜ image sizeë¡œ) ë§Œë“¤ì–´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” upsampling(backwards strided convolution)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. 
ê·¸ëŸ¬ë©´ ê° classë³„ë¡œ denseí•œ segmentation ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, ì›ë˜ imageì˜ í­ì„ W, ë†’ì´ë¥¼ H, ë¼ê³  í•œë‹¤ë©´, WxHx21 ì˜ dense heatmapê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;h4 id=&quot;segmentation&quot;&gt;&lt;em&gt;Segmentation&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ëŠ” ê²°êµ­ ê° class ë³„ ê²°ê³¼ë¥¼ ì¶”ì •í•˜ê³ ì í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆì£ . í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  classì˜ segmentationëœ ê²°ê³¼ë¥¼ ì–»ì–´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë˜ì„œ ìœ— ë‹¨ê³„ì—ì„œ ì–»ì–´ì§„ upsamplingëœ ê° classë³„ heatmapì„ softmaxë¥¼ ì´ìš©í•˜ì—¬ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§€ëŠ” classë§Œ ëª¨ì•„ì„œ í•œì¥ì˜ segmentation ì´ë¯¸ì§€ë¡œ ë§Œë“­ë‹ˆë‹¤.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;skip-combining&quot;&gt;Skip Combining&lt;/h2&gt;
&lt;p&gt;ê·¸ëŸ°ë° 3ë‹¨ê³„ì˜ &lt;strong&gt;&lt;em&gt;Upsampling&lt;/em&gt;&lt;/strong&gt; ê³¼ì •ì—ì„œ coarseí•œ ê²°ê³¼ë¥¼ denseí•˜ê²Œ ë§Œë“¤ì–´ì¤„ ë•Œ ë„ˆë¬´ ë§ì´ ë»¥íŠ€ê¸°ë¥¼ í•˜ê¸° ë•Œë¬¸ì— detailì•„ ë‹¤ ë­‰ê°œì§„ segmenation ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ë°–ì— ì—†ìŠµë‹ˆë‹¤. (ê·¸ë¦¼ 5 ì°¸ê³ )&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2017-12-21-FCN/fig5.jpg&quot; alt=&quot;&quot; /&gt;
Figure 5. Segmentation Result from the Last Conv Layer&lt;/p&gt;

&lt;p&gt;ë‹¤ìŒ ê·¸ë¦¼ 6ê³¼ ê°™ì€ CNN êµ¬ì¡°ì˜ Fully Convolutional Networksê°€ ìˆë‹¤ê³  ê°€ì •í•´ë´…ì‹œë‹¤. ìµœì¢… ê²°ê³¼ë¬¼ì¸ FCN-32sëŠ” 32ë°°ë¡œ upsamplingì„ í•˜ê¸° ë•Œë¬¸ì— detailì´ ë§ì´ ì‚¬ë¼ì§„ segmentation ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2017-12-21-FCN/fig6.jpg&quot; alt=&quot;&quot; /&gt;
Figure 6. (Conventional) Fully Convolutional Networks : FCN-32s&lt;/p&gt;

&lt;p&gt;ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê·¸ ì´ì „ layerì˜ feature mapì„ ì´ìš©í•˜ëŠ” skip combining ê¸°ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤(ê·¸ë¦¼ 7 ì°¸ê³ ).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2017-12-21-FCN/fig7.jpg&quot; alt=&quot;&quot; /&gt;
Figure 7. Fully Convolutional Networks with Skip Combining : FCN-16s&lt;/p&gt;

&lt;p&gt;ê·¸ë¦¼ 6ì—ì„œëŠ” ë§ˆì§€ë§‰ conv layerì¸ conv 7ì—ì„œ 32ë°° upsamplingí•˜ì—¬ segmentation ê²°ê³¼ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ, ê·¸ë¦¼ 7ì—ì„œëŠ” ë§ˆì§€ë§‰ conv layer ê²°ê³¼ë¥¼ 2ë°° upsampling í•˜ê³  ë§ˆì§€ë§‰ pooling layer (pool5)ì´ì „ ë‹¨ê³„ ì¦‰, pool 4 layerì˜ ê²°ê³¼ì™€ í•©ì³ì¤ë‹ˆë‹¤. ê·¸ë¦¬ê³  ë‚œ í›„, ê·¸ í•©ì³ì§„ ê²°ê³¼ë¥¼ 16ë°° upsampling í•˜ì—¬ FCN-16s ë¼ëŠ” segmentation ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ ëƒ…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;ì—¬ê¸°ì„œ í•©ì¹œë‹¤ëŠ” ë§ì€ ê·¸ëƒ¥ &lt;strong&gt;ë”í•´ì¤€ë‹¤&lt;/strong&gt;ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤. 
&lt;a href=&quot;https://github.com/shekkizh/FCN.tensorflow/blob/master/FCN.py&quot;&gt;ë‹¤ìŒ ì½”ë“œ&lt;/a&gt;ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2017-12-21-FCN/fig7.code.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;ê·¸ë ‡ë‹¤ë©´ í•˜ë‚˜ ë” ì´ì „ì˜ pooling layerì™€ë„ í•©ì¹  ìˆ˜ ìˆì§€ ì•Šì„ê¹Œìš”? ë‹¹ì—°íˆ ìˆìŠµë‹ˆë‹¤.
ê·¸ë¦¼ 8ì€ pool 3 layer + 2ë°° upsamplingëœ pool 4 layer + 4ë°° upsampling ëœ conv7 layer ê°’ì„ ë‹¤ì‹œ 8ë°° upsampling í•˜ì—¬ FCN-8së¼ëŠ” ë³´ë‹¤ detailí•œ segmentation ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2017-12-21-FCN/fig8.jpg&quot; alt=&quot;&quot; /&gt;
Figure 8. Fully Convolutional Networks with Skip Combining : FCN-8s&lt;/p&gt;

&lt;p&gt;ì ê·¸ëŸ¬ë©´ ê° skip combining í•œ í›„ì˜ ìµœì¢… segmentation ê²°ê³¼ë¥¼ ì‚´í´ë³¼ê¹Œìš”? í™•ì‹¤íˆ FCN-32sì— ë¹„í•´ FCN-16sê°€, FCN-16sì— ë¹„í•´ FCN-8sê°€ detailí•œ segmentation ê²°ê³¼ë¥¼ ë³´ì—¬ì¤Œì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/images/posts/2017-12-21-FCN/fig9.jpg&quot; alt=&quot;&quot; /&gt;
Figure 9. Segmentation Results&lt;/p&gt;</content><author><name>ê¹€ìŠ¹ì¼</name></author><category term="ë…¼ë¬¸ ë¦¬ë·°" /><summary type="html">ë…¼ë¬¸ ë§í¬ : Fully Convolutional Networks for Semantic Segmentation</summary></entry></feed>